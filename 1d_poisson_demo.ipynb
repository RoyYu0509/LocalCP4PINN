{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d0d5df",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd25c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_pde.utils_pde_poisson import Poisson1D\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "torch.set_num_threads(4)\n",
    "seed = 259\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "# Analytical solution\n",
    "u_star = lambda x: np.sin(math.pi * x)\n",
    "\n",
    "# Define source function: f(x) = -π² sin(πx)\n",
    "def f_func(x):\n",
    "    return -(math.pi**2) * torch.sin(math.pi * x)\n",
    "\n",
    "# Data noise\n",
    "data_noise = 0.15\n",
    "\n",
    "# Instantiate Poisson PDE problem\n",
    "pde = Poisson1D(f_func=f_func, \n",
    "                bc_values=(torch.tensor([[0.0]]), torch.tensor([[0.0]])),\n",
    "                domain=(0,1), true_solution=u_star)\n",
    "\n",
    "# Generate training and testing da|ta of the poisson function\n",
    "(X_train, Y_train) = pde.data_generation(60, data_noise)\n",
    "(X_test, Y_test) = pde.data_generation(50, data_noise)\n",
    "(X_calibration, Y_calibration) = pde.data_generation(30, data_noise)\n",
    "\n",
    "# Collocation points in (0,1)\n",
    "x_colloc_num = 200\n",
    "\n",
    "\n",
    "# NOT USED ####\n",
    "# x_collocation = torch.linspace(0.0, 1.0, steps=x_colloc_num).view(-1, 1)\n",
    "# x_collocation = x_collocation[(x_collocation > 0) & (x_collocation < 1)].view(-1, 1)\n",
    "# NOT USED ####\n",
    "\n",
    "# Alpha\n",
    "alpha=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6058bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_tools.utils_result_viz import plot_truth_and_samples_1D\n",
    "\n",
    "# plot_truth_and_samples_1D(\n",
    "#     x0     = 0,\n",
    "#     x1     = 1,\n",
    "#     X_train   = X_train,\n",
    "#     Y_train   = Y_train,\n",
    "#     true_solution=u_star,\n",
    "#     x_colloc = x_collocation, # NOT USED ####\n",
    "#     title     = \"Underdamped oscillator: ground-truth vs noisy data\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd4baf",
   "metadata": {},
   "source": [
    "# UQ Model with VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1825b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "vibpinn = VIBPINN(\n",
    "    pde,\n",
    "    1,[25, 35, 35, 25], 1,\n",
    "    mu_std = 0.05, rho = -5.5, prior_std=10.0, init_data_noise=0.50\n",
    ")\n",
    "loss_dict = vibpinn.fit(x_colloc_num, X_train=X_train, Y_train=Y_train, epochs=5000, lr=1e-3,\n",
    "                               λ_pde=3.0,λ_data=5.0,λ_bc=10.0,scheduler_kwargs={'step_size': 3000, 'gamma': 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "grid_test = torch.linspace(0, 1, 100).view(-1, 1)\n",
    "uncal_predset = vibpinn.predict(alpha, grid_test)\n",
    "\n",
    "# Visualization\n",
    "from utils_tools.utils_result_viz import plot_predictions_1D\n",
    "plot_predictions_1D(grid_test, uncal_predset, u_star, X=X_train, Y=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6d0ac",
   "metadata": {},
   "source": [
    "# CP VI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b61a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_cp import CP\n",
    "cp_vi = CP(vibpinn)\n",
    "\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"raw_std\",              \n",
    "}\n",
    "cal_predset = cp_vi.predict(alpha, grid_test, **cp_pred_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ca9bb0",
   "metadata": {},
   "source": [
    "# Plot the CP effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86833431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Intervals\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import to_hex\n",
    "import numpy as np\n",
    "import os\n",
    "seed = 62912\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "(X_test, Y_test) = pde.data_generation(75, data_noise)\n",
    "# ------------ choose the same colormap as your 2D function ------------\n",
    "cmap_name = \"viridis\"\n",
    "vir = plt.get_cmap(cmap_name)\n",
    "\n",
    "# sampled colors from viridis (same stops used across my suggestions)\n",
    "COL_NAIV = \"#f7c5c8\"   # Blue  \n",
    "COL_MEAN = \"#b13c32\"   \n",
    "COL_CP   = \"#abccf4\"   # teal\n",
    "COL_TRUE = \"#222222\"   # yellow\n",
    "COL_SCAT = \"#f6d09f\"\n",
    "COL_EDGE = \"#222222\"           # axes/marker edge\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"axes.edgecolor\": COL_EDGE, \"axes.labelcolor\": COL_EDGE,\n",
    "    \"xtick.color\": COL_EDGE,    \"ytick.color\": COL_EDGE,\n",
    "    \"axes.linewidth\": 1.0,\n",
    "    \"legend.framealpha\": 0.96,  \"legend.facecolor\": \"white\",\n",
    "    \"legend.edgecolor\": COL_EDGE,\n",
    "    \"font.size\": 11,\n",
    "})\n",
    "\n",
    "# ------------ unpack + prep ------------\n",
    "outdir = \"CP_demo\"; os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "n_lower, n_upper = uncal_predset\n",
    "cp_lower, cp_upper = cal_predset\n",
    "x = np.asarray(grid_test).ravel()\n",
    "\n",
    "n_lower, n_upper = n_lower.ravel(), n_upper.ravel()\n",
    "cp_lower, cp_upper = cp_lower.ravel(), cp_upper.ravel()\n",
    "\n",
    "pred_mean = (cp_lower + cp_upper) / 2.0          # mean line (calibrated)\n",
    "true_solution_np = u_star(grid_test).ravel()\n",
    "\n",
    "# ------------ plot ------------\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "\n",
    "# bands first (wide -> narrow)\n",
    "ax.fill_between(x, n_lower, n_upper, color=COL_NAIV, alpha=1,\n",
    "                label=\"Before CP\", zorder=2)\n",
    "ax.fill_between(x, cp_lower, cp_upper, color=COL_CP, alpha=1,\n",
    "                label=\"After CP\", zorder=1)\n",
    "\n",
    "# mean + truth\n",
    "ax.plot(x, pred_mean, ls=\"--\", lw=2.0, color=COL_MEAN,\n",
    "        label=r\"Prediction\", zorder=5)\n",
    "ax.plot(x, true_solution_np, lw=2.4, color=COL_TRUE,\n",
    "        label=r\"True\", zorder=3)\n",
    "\n",
    "# data points\n",
    "ax.scatter(X_test, Y_test, s=40, facecolor=COL_SCAT, edgecolor=COL_EDGE,\n",
    "           linewidth=0.7, label=\"Data\", zorder=4)\n",
    "\n",
    "ax.set_xlabel(r\"x\", fontsize=14)\n",
    "ax.set_ylabel(r\"$u()$\", fontsize=14, rotation=0)\n",
    "ax.margins(x=0)\n",
    "ax.legend(loc=\"lower center\", handlelength=1.6, borderpad=0.6)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(outdir, \"uncal_vs_cal.pdf\"), bbox_inches=\"tight\")\n",
    "fig.savefig(os.path.join(outdir, \"uncal_vs_cal.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f630ccc4",
   "metadata": {},
   "source": [
    "# Test Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af62189",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _coverage(pred_set, y_true):\n",
    "    \"\"\"\n",
    "    Empirical coverage:  fraction of targets that fall inside the\n",
    "    predicted interval.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred_set : array-like, shape (2, N)  OR  (N, 2)\n",
    "        Row/column order doesn’t matter as long as lower < upper.\n",
    "    y_true   : array-like, shape (N,)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float   in the range [0, 1]\n",
    "    \"\"\"\n",
    "    lower, upper = pred_set[0].flatten(), pred_set[1].flatten()\n",
    "    y_true = y_true.to(lower.device).flatten()\n",
    "    inside = (y_true >= lower) & (y_true <= upper)\n",
    "    return inside.float().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_predset = cp_vi.predict(alpha, X_test, **cp_pred_kwargs)\n",
    "_coverage(cal_predset, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_predset = vibpinn.predict(alpha, X_test)\n",
    "_coverage(uncal_predset, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149ab94",
   "metadata": {},
   "source": [
    "# Test model's metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2f7899",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_result_metrics import cp_test_uncertainties, vi_test_uncertainties\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(20)\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":vi_model, \n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test\n",
    "}\n",
    "\n",
    "\n",
    "cp_testing_args = {\n",
    "        \"alphas\":alphas, \n",
    "        \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "        \"heuristic_u\":\"raw_std\", # Change base on if the baseline model has its original uq band\n",
    "        \"k\":20\n",
    "}\n",
    "\n",
    "\n",
    "vi_bpinn_df_uncal = vi_test_uncertainties(uqmodel=vibpinn, **baseline_testing_args)\n",
    "vi_bpinn_df_cal = cp_test_uncertainties(cp_vi, **cp_testing_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865d9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vi_bpinn_df_both = pd.concat([\n",
    "    vi_bpinn_df_uncal.assign(calibration='uncalibrated'),\n",
    "    vi_bpinn_df_cal.assign(calibration='calibrated')\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f97eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_bpinn_df_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe93be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_bpinn_df_uncal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6695e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_grid_2x2(\n",
    "    named_pairs,\n",
    "    *,\n",
    "    labels=(\"Before CP\", \"After CP\"),\n",
    "    grid_figsize=(20, 5),\n",
    "    suptitle=None,\n",
    "    model_title_size=23,\n",
    "):\n",
    "    \"\"\"\n",
    "    named_pairs: list or dict of exactly 4 items like:\n",
    "        [(\"Model A\", df_uncal_A, df_cal_A), ...]\n",
    "        OR {\"Model A\": (df_uncal_A, df_cal_A), ...}\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # --- same prep as in plot_coverage_comparison ---\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    # normalize input\n",
    "    items = list(named_pairs.items()) if isinstance(named_pairs, dict) else list(named_pairs)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 4, figsize=grid_figsize)\n",
    "\n",
    "    i = 0\n",
    "    for ax, (name, df_uncal, df_cal) in zip(axs.ravel(), items):\n",
    "        # --- begin: copied body of plot_coverage_comparison (minimal version) ---\n",
    "        exp1, emp1 = _prep(df_uncal)\n",
    "        exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "        # curves + ideal\n",
    "        ax.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\", ms=11, lw=4, label=labels[0])\n",
    "        ax.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\", ms=17, lw=4, label=labels[1])\n",
    "        ax.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "        i+=1\n",
    "        if i <= 1:\n",
    "            # limits & labels\n",
    "            ax.autoscale(enable=True, tight=False)\n",
    "            ax.margins(x=0.02, y=0.02)      # tiny padding so endpoints aren’t cramped\n",
    "            ax.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=16)\n",
    "            ax.set_ylabel(\"Empirical Coverage\", fontsize=16)\n",
    "            ax.legend(loc='upper left', fontsize=14)\n",
    "            # --- end: copied body ---\n",
    "\n",
    "            # subplot title = model name\n",
    "            ax.set_title(name, fontsize=model_title_size)\n",
    "        else:\n",
    "            ax.autoscale(enable=True, tight=False)\n",
    "            ax.margins(x=0.02, y=0.02)      # tiny padding so endpoints aren’t cramped\n",
    "            ax.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=16)\n",
    "            # --- end: copied body ---\n",
    "            ax.yaxis.set_visible(False)\n",
    "            # subplot title = model name\n",
    "            ax.set_title(name, fontsize=model_title_size)\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=model_title_size + 2)\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    else:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b1aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"VI\",      vi_bpinn_df_uncal, vi_bpinn_df_cal),\n",
    "]\n",
    "fig, axs = plot_coverage_grid_2x2(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b076796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the coverage deviation using mae\n",
    "def prepare_coverage_data(df):\n",
    "    expected = 1 - df[\"alpha\"]\n",
    "    empirical = df[\"coverage\"]\n",
    "    exp_full = pd.concat([pd.Series([0.0]), expected, pd.Series([1.0])], ignore_index=True)\n",
    "    emp_full = pd.concat([pd.Series([0.0]), empirical, pd.Series([1.0])], ignore_index=True)\n",
    "    sort_idx = exp_full.argsort()\n",
    "    exp_sorted, emp_sorted = exp_full[sort_idx], emp_full[sort_idx]\n",
    "    return exp_sorted.to_numpy(), emp_sorted.to_numpy()\n",
    "\n",
    "def coverage_deviation(exp, emp, how=\"mae\"):\n",
    "    diff = np.abs(emp - exp)\n",
    "    if   how == \"mae\":  return diff.mean()\n",
    "    elif how == \"rmse\": return np.sqrt((diff**2).mean())\n",
    "    elif how == \"max\":  return diff.max()\n",
    "    else:\n",
    "        raise ValueError(\"metric must be 'mae', 'rmse', or 'max'\")\n",
    "\n",
    "exp1, emp1 = prepare_coverage_data(vi_bpinn_df_uncal)\n",
    "exp2, emp2 = prepare_coverage_data(vi_bpinn_df_cal)\n",
    "dev1 = coverage_deviation(exp1, emp1)  # Using the default metrics\n",
    "dev2 = coverage_deviation(exp2, emp2)  # Using the default metrics\n",
    "print(f\"Uncal dev:{dev1}\")\n",
    "print(f\"Cal dev:{dev2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20cfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot_compare_df = pd.DataFrame({\n",
    "    'model': {'1':\"Before CP\", '2': \"After CP\"},\n",
    "    'ACD': {'1': 0.2866, '2': 0.0870},\n",
    "    'Coverage': {'1': 0.43, '2': 0.96},\n",
    "    'Sharpness': {'1': 0.1886, '2': 0.7403},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f8ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def plot_cp_split_bars(df,\n",
    "                       metrics_group1=('Coverage','Sharpness'),\n",
    "                       metrics_group2=('ACD',),\n",
    "                       model_col='model',\n",
    "                       model_order=('Before CP','After CP'),\n",
    "                       colors=(COL_NAIV, COL_CP),\n",
    "                       bar_width_group1=0.35,\n",
    "                       bar_width_group2=0.20,   # narrower bars for ACD\n",
    "                       width_ratios=(2,1)):     # adjust subplot widths\n",
    "    \"\"\"\n",
    "    Plot grouped bar charts in two panels:\n",
    "      - Left: Coverage + Sharpness\n",
    "      - Right: ACD\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[model_col] = pd.Categorical(df[model_col], categories=model_order, ordered=True)\n",
    "    agg = df.groupby(model_col, observed=True).mean(numeric_only=True)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6.5,5),\n",
    "                            gridspec_kw={'width_ratios': width_ratios})\n",
    "\n",
    "    def plot_group(ax, metrics, bar_width):\n",
    "        x = np.arange(len(metrics))\n",
    "        for i, model in enumerate(model_order):\n",
    "            ys = [agg.loc[model, m] for m in metrics]\n",
    "            pos = x + (i-0.5)*bar_width\n",
    "            bars = ax.bar(pos, ys, width=bar_width, label=model, color=colors[i])\n",
    "            for rect, y in zip(bars, ys):\n",
    "                ax.annotate(f\"{y:.2f}\",\n",
    "                            xy=(rect.get_x()+rect.get_width()/2, y),\n",
    "                            xytext=(0,3), textcoords=\"offset points\",\n",
    "                            ha='center', va='bottom', fontsize=9)\n",
    "        ax.set_xticks(x, metrics)\n",
    "        ax.yaxis.grid(True, linestyle=\":\", alpha=0.6)\n",
    "        ymin, ymax = ax.get_ylim()\n",
    "        ax.set_ylim(ymin, ymax * 1.10)\n",
    "\n",
    "    # left: Coverage + Sharpness (use group1 bar width)\n",
    "    plot_group(axs[0], metrics_group1, bar_width_group1)\n",
    "    axs[0].set_title(r\"Coverage & Sharpness at $\\alpha$=0.05\")\n",
    "    axs[0].legend(loc=\"upper right\", frameon=False)\n",
    "\n",
    "    # right: ACD (use group2 bar width)\n",
    "    plot_group(axs[1], metrics_group2, bar_width_group2)\n",
    "    axs[1].set_title(\"ACD\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    # adjust spacing\n",
    "    fig.subplots_adjust(wspace=0.3) \n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e4f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plot_cp_split_bars(\n",
    "    bar_plot_compare_df,\n",
    "    bar_width_group1=0.35,  # wider for Coverage/Sharpness\n",
    "    bar_width_group2=0.1,  # narrower for ACD\n",
    "    width_ratios=(2,0.85)      # also make ACD panel narrower\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d60f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncal_predset = vibpinn.predict(alpha, grid_test)\n",
    "cal_predset = cp_vi.predict(alpha, grid_test, **cp_pred_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94041d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plot_cp_combined_splitbars(\n",
    "    df, \n",
    "    uncal_predset, cal_predset, grid_test, u_star, X_test, Y_test,\n",
    "    metrics_group1=('Coverage',),   # left y-axis\n",
    "    metrics_group2=('ACD',),                   # right y-axis\n",
    "    model_col='model',\n",
    "    model_order=('Before CP','After CP'),\n",
    "    colors=(\"#abccf4\",\"#f7c5c8\"),              # before CP, after CP\n",
    "    bar_width_group1=0.25,                     # used for all bars (uniform width)\n",
    "    bar_width_group2=0.25,                     # kept for API compatibility, ignored\n",
    "    width_ratios=(1.6, 1.4),                   # interval wider, single metrics panel\n",
    "    figsize=(12,5),\n",
    "    outdir=None,\n",
    "    tick_fs=14,\n",
    "    value_fs=10,\n",
    "    legend_fs=12,\n",
    "    y_headroom_left=0.3,                      # extra headroom on left y-axis (15%)\n",
    "    y_headroom_right=0.3,                     # extra headroom on right y-axis (15%)\n",
    "    left_tick_color=\"#590B11\",\n",
    "    right_tick_color=\"#093458\",\n",
    "    # NEW: shaded fills for the two models\n",
    "    bar_hatches=(\"///\", \"...\"),                # Before CP, After CP\n",
    "    edge_linewidth=0.9                          # outline to make hatches pop\n",
    "):\n",
    "    \"\"\"\n",
    "    Two panels:\n",
    "      Left: Interval plot (unchanged)\n",
    "      Right: Combined metrics bar plot with dual y-axes.\n",
    "    Bars use different shaded fills (hatches) for Before/After CP.\n",
    "    Value labels adopt the tick color of their axis (left vs right).\n",
    "    \"\"\"\n",
    "\n",
    "    # ---------- helpers ----------\n",
    "    def _darker(color, factor=0.75):\n",
    "        r, g, b = mcolors.to_rgb(color)\n",
    "        return (r*factor, g*factor, b*factor)\n",
    "\n",
    "    # ---------- prep bar data ----------\n",
    "    df = df.copy()\n",
    "    df[model_col] = pd.Categorical(df[model_col], categories=model_order, ordered=True)\n",
    "    agg = df.groupby(model_col, observed=True).mean(numeric_only=True)\n",
    "\n",
    "    # ---------- figure + axes ----------\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 2, figsize=figsize,\n",
    "        gridspec_kw={'width_ratios': width_ratios}\n",
    "    )\n",
    "    ax_interval, ax_metrics_left = axs\n",
    "    ax_metrics_right = ax_metrics_left.twinx()  # right y-axis for group2\n",
    "\n",
    "    # ---------- Interval plot (unchanged) ----------\n",
    "    n_lower, n_upper = [arr.ravel() for arr in uncal_predset]\n",
    "    cp_lower, cp_upper = [arr.ravel() for arr in cal_predset]\n",
    "    x = np.asarray(grid_test).ravel()\n",
    "    if len(x) != len(n_lower):\n",
    "        raise ValueError(\"grid_test length does not match prediction length.\")\n",
    "\n",
    "    pred_mean = (cp_lower + cp_upper) / 2.0\n",
    "    true_solution_np = u_star(grid_test).ravel()\n",
    "\n",
    "    COL_NAIV, COL_CP = colors\n",
    "    COL_MEAN, COL_TRUE, COL_SCAT, COL_EDGE = \"#b13c32\", \"#222222\", \"#f6d09f\", \"#222222\"\n",
    "\n",
    "    ax_interval.fill_between(x, n_lower, n_upper, color=COL_NAIV, alpha=1,\n",
    "                             label=\"Before CP\", zorder=2)\n",
    "    ax_interval.fill_between(x, cp_lower, cp_upper, color=COL_CP, alpha=1,\n",
    "                             label=\"After CP\", zorder=1)\n",
    "    ax_interval.plot(x, pred_mean, ls=\"--\", lw=2.0, color=COL_MEAN,\n",
    "                     label=\"Prediction\", zorder=5)\n",
    "    ax_interval.plot(x, true_solution_np, lw=2.4, color=COL_TRUE,\n",
    "                     label=\"True\", zorder=3)\n",
    "    ax_interval.scatter(X_test, Y_test, s=40, facecolor=COL_SCAT, edgecolor=COL_EDGE,\n",
    "                        linewidth=0.7, label=\"Data\", zorder=4)\n",
    "    ax_interval.set_xlabel(r\"x\", fontsize=15)\n",
    "    ax_interval.set_ylabel(r\"$u$\", fontsize=15)\n",
    "    ax_interval.margins(x=0)\n",
    "    ax_interval.legend(loc=\"lower center\", handlelength=1.6, borderpad=0.6, fontsize=13)\n",
    "    ymin_i, ymax_i = ax_interval.get_ylim()\n",
    "    ax_interval.set_ylim(ymin_i, ymax_i*1.10)\n",
    "\n",
    "    # ---------- Combined metrics bar plot with twin y-axes ----------\n",
    "    metrics_all = list(metrics_group1) + list(metrics_group2)\n",
    "    n_metrics = len(metrics_all)\n",
    "    x_all = np.arange(n_metrics)\n",
    "\n",
    "    # Use one uniform bar width for all metrics\n",
    "    bar_w = bar_width_group1\n",
    "    offset = (np.arange(len(model_order)) - (len(model_order) - 1)/2.0) * bar_w\n",
    "\n",
    "    # helper to annotate bars with axis-colored text\n",
    "    def _annotate(ax, bars, values, text_color):\n",
    "        for rect, y in zip(bars, values):\n",
    "            ax.annotate(f\"{y:.2f}\",\n",
    "                        xy=(rect.get_x() + rect.get_width()/2, y),\n",
    "                        xytext=(0, 3), textcoords=\"offset points\",\n",
    "                        ha=\"center\", va=\"bottom\", fontsize=value_fs,\n",
    "                        color=text_color, zorder=5)\n",
    "\n",
    "    # Plot bars metric-by-metric, choosing axis based on membership\n",
    "    left_vals_max = 0.0\n",
    "    right_vals_max = 0.0\n",
    "    handles_all, labels_all = [], []\n",
    "\n",
    "    for mi, metric in enumerate(metrics_all):\n",
    "        is_left = metric in metrics_group1\n",
    "        ax_here = ax_metrics_left if is_left else ax_metrics_right\n",
    "        label_color = left_tick_color if is_left else right_tick_color\n",
    "\n",
    "        ys_by_model = [agg.loc[model, metric] for model in model_order]\n",
    "\n",
    "        bars = []\n",
    "        for i, model in enumerate(model_order):\n",
    "            xpos = x_all[mi] + offset[i]\n",
    "            edge_c = _darker(colors[i], 0.72)\n",
    "            b = ax_here.bar(\n",
    "                xpos, ys_by_model[i], width=bar_w,\n",
    "                label=model, color=colors[i],\n",
    "                hatch=(bar_hatches[i] if i < len(bar_hatches) else None),\n",
    "                edgecolor=edge_c, linewidth=edge_linewidth, zorder=2\n",
    "            )\n",
    "            bars.extend(b)\n",
    "\n",
    "        _annotate(ax_here, bars, ys_by_model, label_color)\n",
    "\n",
    "        if is_left:\n",
    "            left_vals_max = max(left_vals_max, max(ys_by_model))\n",
    "        else:\n",
    "            right_vals_max = max(right_vals_max, max(ys_by_model))\n",
    "\n",
    "        h, l = ax_here.get_legend_handles_labels()\n",
    "        handles_all += h\n",
    "        labels_all += l\n",
    "\n",
    "    # xticks uniformly for all metrics\n",
    "    ax_metrics_left.set_xticks(x_all, metrics_all, fontsize=tick_fs)\n",
    "\n",
    "    # y ticks/labels + colors\n",
    "    ax_metrics_left.set_ylabel(\"Coverage\", fontsize=13, color=left_tick_color,labelpad=8)\n",
    "    ax_metrics_right.set_ylabel(\"ACD\", fontsize=13, color=right_tick_color,labelpad=8)\n",
    "    ax_metrics_left.tick_params(axis='y', colors=left_tick_color)\n",
    "    ax_metrics_right.tick_params(axis='y', colors=right_tick_color)\n",
    "\n",
    "    # y-lims with extra headroom\n",
    "    if left_vals_max == 0:\n",
    "        left_vals_max = 1.0\n",
    "    if right_vals_max == 0:\n",
    "        right_vals_max = 1.0\n",
    "    ax_metrics_left.set_ylim(0, left_vals_max * (1.0 + y_headroom_left))\n",
    "    ax_metrics_right.set_ylim(0, right_vals_max * (1.0 + y_headroom_right))\n",
    "\n",
    "    # x-lims so bars aren't cramped\n",
    "    ax_metrics_left.set_xlim(-0.5, n_metrics - 0.5)\n",
    "\n",
    "    # deduplicate legend entries\n",
    "    by_label = {}\n",
    "    for h, l in zip(handles_all, labels_all):\n",
    "        if l not in by_label:\n",
    "            by_label[l] = h\n",
    "    ax_metrics_left.legend(by_label.values(), by_label.keys(),\n",
    "                           loc=\"upper center\", frameon=True, fontsize=legend_fs)\n",
    "\n",
    "    # slight x padding\n",
    "    ax_metrics_left.margins(x=0.03)\n",
    "\n",
    "    # layout + save\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    if outdir:\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        fig.savefig(os.path.join(outdir, \"combined_dualaxis_uniform.pdf\"), bbox_inches=\"tight\")\n",
    "        fig.savefig(os.path.join(outdir, \"combined_dualaxis_uniform.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    return fig, (ax_interval, ax_metrics_left)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef0e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cp_combined_splitbars(\n",
    "    bar_plot_compare_df, \n",
    "    uncal_predset, cal_predset, grid_test, u_star, X_test, Y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_tuning import save_plot\n",
    "save_plot(\n",
    "    plot_cp_combined_splitbars,\n",
    "    save_dir=\"CP_demo\", prefix=\"uncal_vs_cal\",\n",
    ")(\n",
    "    bar_plot_compare_df, \n",
    "    uncal_predset, cal_predset, grid_test, u_star, X_test, Y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
