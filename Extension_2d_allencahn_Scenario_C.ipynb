{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ca3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_extension_vis_2d import estimate_true_error_local_max, plot_2D_comparison_with_coverage_error_compare, visualize_selected_points, plot_metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5046df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Sequence, Literal, Dict, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def add_gaussian_noise_xy(  # name kept for drop-in; now supports L-shape with smoothing\n",
    "    xy: torch.Tensor,                 # (N, 2)\n",
    "    u: torch.Tensor,                  # (N, 1) or (N,)\n",
    "    *,\n",
    "    centers: Sequence[Sequence[float]],\n",
    "    radii: float | Sequence[float] | Sequence[Sequence[float]],\n",
    "    sigmas: float | Sequence[float],\n",
    "    base_sigma: float = 0.0,          # background noise std\n",
    "    index_eps: float = 1e-6,          # kept for backward-compat; NOT used for idx anymore\n",
    "    generator: torch.Generator | None = None,\n",
    "    clamp: tuple[float, float] | None = None,\n",
    "    return_sigma: bool = False,\n",
    "    combine: Literal[\"sum\", \"max\", \"quadrature\"] = \"sum\",\n",
    "    edge_tau: float = 0.05,           # softness of boundary: normalized (islands) or absolute (L-shape)\n",
    "    # ===== NEW: optional L-shape region =====\n",
    "    l_shape: Optional[Dict[str, object]] = None,\n",
    "    # ===== NEW: index controls =====\n",
    "    l_shape_in_idx: bool = True,     # include L-shape interior in idx if True\n",
    "    index_margin: float = -0.05,        # <-- DISC/ELLIPSE margin (normalized in d-units)\n",
    "    l_index_margin: float = -0.1,      # <-- L-SHAPE margin (absolute XY units)\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds heteroscedastic noise with smoothed regions (islands + optional L-shape).\n",
    "    - Noise uses soft weights (sigmoid with edge_tau).\n",
    "    - Indices `idx` are strict geometry with optional margins:\n",
    "        * Discs/Ellipses: d < 1 - index_margin        (index_margin in normalized radial units)\n",
    "        * L-shape:        sdf_L < -l_index_margin     (l_index_margin in XY units)\n",
    "      Set l_shape_in_idx=True to include L-shape in idx.\n",
    "    \"\"\"\n",
    "    # --- shape checks / normalize ---\n",
    "    if xy.ndim != 2 or xy.shape[1] != 2:\n",
    "        raise ValueError(\"xy must have shape (N, 2)\")\n",
    "    u = u.reshape(-1, 1)\n",
    "    if xy.shape[0] != u.shape[0]:\n",
    "        raise ValueError(\"xy and u must have the same number of points (N)\")\n",
    "\n",
    "    device, dtype = u.device, u.dtype\n",
    "    XY = xy.to(device=device, dtype=dtype)\n",
    "\n",
    "    # Utility: rectangle signed distance function for axis-aligned box [x0, x1] Ã— [y0, y1]\n",
    "    def _sdf_rect(xy_: torch.Tensor, x0, x1, y0, y1) -> torch.Tensor:\n",
    "        x = xy_[:, 0]\n",
    "        y = xy_[:, 1]\n",
    "        dx_out = torch.maximum(x0 - x, x - x1).clamp_min(0)\n",
    "        dy_out = torch.maximum(y0 - y, y - y1).clamp_min(0)\n",
    "        outside_dist = torch.sqrt(dx_out * dx_out + dy_out * dy_out)\n",
    "        inside_mask = (x >= x0) & (x <= x1) & (y >= y0) & (y <= y1)\n",
    "        dist_to_edges = torch.minimum(torch.minimum(x - x0, x1 - x),\n",
    "                                      torch.minimum(y - y0, y1 - y))\n",
    "        inside_dist = -dist_to_edges\n",
    "        return torch.where(inside_mask, inside_dist, outside_dist)\n",
    "\n",
    "    # Build a list of (weights, amplitudes) from islands and/or L-shape\n",
    "    W_list = []\n",
    "    S_list = []\n",
    "\n",
    "    # -------- Islands (original behavior) --------\n",
    "    C = torch.as_tensor(centers, dtype=dtype, device=device).reshape(-1, 2)  # (K,2)\n",
    "    K = C.shape[0]\n",
    "\n",
    "    d_norm = None   # normalized distance to discs/ellipses (for idx)\n",
    "\n",
    "    if K > 0:\n",
    "        # amplitudes per island\n",
    "        S_islands = (torch.full((K,), float(sigmas), dtype=dtype, device=device)\n",
    "                     if isinstance(sigmas, (int, float))\n",
    "                     else torch.as_tensor(sigmas, dtype=dtype, device=device).reshape(-1))\n",
    "        if S_islands.numel() != K:\n",
    "            raise ValueError(\"For islands, sigmas must be scalar or length == len(centers)\")\n",
    "\n",
    "        # radii: scalar, (K,), or (K,2)\n",
    "        R_raw = torch.as_tensor(radii, dtype=dtype, device=device)\n",
    "        if R_raw.ndim == 0:\n",
    "            R_iso = R_raw.expand(K)    # isotropic radius shared by all\n",
    "            R_aniso = None\n",
    "        elif R_raw.ndim == 1:\n",
    "            if R_raw.numel() != K:\n",
    "                raise ValueError(\"radii 1D must have length == len(centers)\")\n",
    "            R_iso = R_raw\n",
    "            R_aniso = None\n",
    "        elif R_raw.ndim == 2 and R_raw.shape == (K, 2):\n",
    "            R_iso = None\n",
    "            R_aniso = R_raw\n",
    "        else:\n",
    "            raise ValueError(\"radii must be scalar, length-K, or shape (K,2) for anisotropic\")\n",
    "\n",
    "        # compute normalized distance and soft weights\n",
    "        diff = XY[:, None, :] - C[None, :, :]          # (N,K,2)\n",
    "        tiny = torch.finfo(dtype).tiny\n",
    "        if R_aniso is None:\n",
    "            R2 = (R_iso.clamp_min(tiny)) ** 2          # (K,)\n",
    "            Q  = (diff.pow(2).sum(dim=2)) / R2[None, :]   # (N,K)\n",
    "        else:\n",
    "            R2 = (R_aniso.clamp_min(tiny)) ** 2        # (K,2)\n",
    "            Q  = (diff.pow(2) / R2[None, :, :]).sum(dim=2)  # (N,K)\n",
    "\n",
    "        d_norm = Q.clamp_min(0).sqrt()                 # normalized radial distance\n",
    "        tau_norm = max(float(edge_tau), 1e-12)\n",
    "        w_islands = torch.sigmoid((1.0 - d_norm) / tau_norm).to(dtype)  # (N,K)\n",
    "        W_list.append(w_islands)\n",
    "        S_list.append(S_islands)\n",
    "\n",
    "    # -------- L-shape (NEW) --------\n",
    "    sdf_L = None  # keep for idx if requested\n",
    "    if l_shape is not None:\n",
    "        # Parse parameters\n",
    "        corner: Tuple[float, float] = tuple(l_shape.get(\"corner\", (0.5, 0.5)))  # inner corner\n",
    "        lengths: Tuple[float, float] = tuple(l_shape.get(\"lengths\", (0.5, 0.5)))  # (Lx, Ly)\n",
    "        thickness: float = float(l_shape.get(\"thickness\", 0.2))\n",
    "        orientation: str = str(l_shape.get(\"orientation\", \"NE\")).upper()\n",
    "        # Amplitude for L-shape (falls back to scalar sigmas or first elem)\n",
    "        if \"sigma\" in l_shape:\n",
    "            S_L_val = float(l_shape[\"sigma\"])\n",
    "        else:\n",
    "            if isinstance(sigmas, (int, float)):\n",
    "                S_L_val = float(sigmas)\n",
    "            else:\n",
    "                S_L_val = float(torch.as_tensor(sigmas, dtype=dtype).reshape(-1)[0].item())\n",
    "\n",
    "        cx, cy = corner\n",
    "        Lx, Ly = lengths\n",
    "        t = thickness\n",
    "        if t <= 0 or Lx <= 0 or Ly <= 0:\n",
    "            raise ValueError(\"l_shape: thickness and lengths must be positive.\")\n",
    "\n",
    "        # Build rectangles H (horizontal arm) and V (vertical arm)\n",
    "        if orientation == \"NE\":\n",
    "            x0_h, x1_h, y0_h, y1_h = cx, cx + Lx, cy, cy + t\n",
    "            x0_v, x1_v, y0_v, y1_v = cx, cx + t,  cy, cy + Ly\n",
    "        elif orientation == \"NW\":\n",
    "            x0_h, x1_h, y0_h, y1_h = cx - Lx, cx, cy, cy + t\n",
    "            x0_v, x1_v, y0_v, y1_v = cx - t,  cx,  cy, cy + Ly\n",
    "        elif orientation == \"SE\":\n",
    "            x0_h, x1_h, y0_h, y1_h = cx, cx + Lx, cy - t, cy\n",
    "            x0_v, x1_v, y0_v, y1_v = cx, cx + t,  cy - Ly, cy\n",
    "        elif orientation == \"SW\":\n",
    "            x0_h, x1_h, y0_h, y1_h = cx - Lx, cx, cy - t, cy\n",
    "            x0_v, x1_v, y0_v, y1_v = cx - t,  cx,  cy - Ly, cy\n",
    "        else:\n",
    "            raise ValueError(\"l_shape['orientation'] must be one of {'NE','NW','SE','SW'}.\")\n",
    "\n",
    "        # Signed distance to union of rectangles = min(sdf(H), sdf(V))\n",
    "        sdf_h = _sdf_rect(XY, x0_h, x1_h, y0_h, y1_h)\n",
    "        sdf_v = _sdf_rect(XY, x0_v, x1_v, y0_v, y1_v)\n",
    "        sdf_L = torch.minimum(sdf_h, sdf_v)\n",
    "\n",
    "        tau_abs = max(float(edge_tau), 1e-12)  # absolute units for L-shape\n",
    "        w_L = torch.sigmoid(-sdf_L / tau_abs).to(dtype).unsqueeze(1)  # (N,1)\n",
    "        W_list.append(w_L)\n",
    "        S_list.append(torch.as_tensor([S_L_val], dtype=dtype, device=device))\n",
    "\n",
    "    # If neither islands nor L-shape were provided -> background only\n",
    "    if len(W_list) == 0:\n",
    "        sigma = torch.full_like(u, float(base_sigma))\n",
    "        noise = torch.normal(mean=torch.zeros_like(u), std=sigma, generator=generator)\n",
    "        u_noisy = u + noise\n",
    "        if clamp is not None:\n",
    "            lo, hi = clamp\n",
    "            u_noisy = u_noisy.clamp(min=lo, max=hi)\n",
    "        idx = torch.zeros(0, dtype=torch.long, device=device)\n",
    "        return (u_noisy, sigma, idx) if return_sigma else (u_noisy, idx)\n",
    "\n",
    "    # Concatenate all contributions and aggregate by rule\n",
    "    W = torch.cat(W_list, dim=1)                     # (N, M)\n",
    "    S_all = torch.cat([s.reshape(-1) for s in S_list])  # (M,)\n",
    "\n",
    "    if combine == \"sum\":\n",
    "        add = W * S_all[None, :]                     # (N, M)\n",
    "        sigma = add.sum(dim=1, keepdim=True) + float(base_sigma)\n",
    "    elif combine == \"max\":\n",
    "        add = W * S_all[None, :]\n",
    "        sigma = add.max(dim=1, keepdim=True).values + float(base_sigma)\n",
    "    elif combine == \"quadrature\":\n",
    "        add = (W * S_all[None, :]) ** 2\n",
    "        sigma = (add.sum(dim=1, keepdim=True) + float(base_sigma) ** 2).sqrt()\n",
    "    else:\n",
    "        raise ValueError(\"combine must be one of: 'sum', 'max', 'quadrature'\")\n",
    "\n",
    "    sigma = sigma.clamp_min(0)\n",
    "\n",
    "    # ====================== IDX CONTROL (customizable margins here) ======================\n",
    "    # Discs/Ellipses: select strictly inside with optional normalized margin.\n",
    "    #   threshold_d = 1.0 - index_margin\n",
    "    #   (index_margin = 0 selects full interior; >0 shrinks the selected core)\n",
    "    inside_island = torch.zeros(XY.shape[0], dtype=torch.bool, device=device)\n",
    "    if K > 0:\n",
    "        thr = 1.0 - float(index_margin)   # <<< adjust disc/ellipse margin here\n",
    "        inside_island = (d_norm < thr).any(dim=1)\n",
    "\n",
    "    # L-shape: include in idx only if requested; margin is absolute (XY units).\n",
    "    inside_L = torch.zeros_like(inside_island)\n",
    "    if (l_shape is not None) and l_shape_in_idx and (sdf_L is not None):\n",
    "        # Points strictly inside are sdf_L < 0; margin shrinks by requiring sdf_L < -l_index_margin\n",
    "        inside_L = (sdf_L < -float(l_index_margin))   # <<< adjust L-shape margin here\n",
    "\n",
    "    # Union depending on what's enabled\n",
    "    inside_any = inside_island | inside_L\n",
    "    idx = torch.nonzero(inside_any, as_tuple=False).squeeze(1)\n",
    "    # ==================== END IDX CONTROL (customizable margins above) ===================\n",
    "\n",
    "    # Sample and add noise\n",
    "    noise = torch.normal(mean=torch.zeros_like(u), std=sigma, generator=generator)\n",
    "    u_noisy = u + noise\n",
    "    if clamp is not None:\n",
    "        lo, hi = clamp\n",
    "        u_noisy = u_noisy.clamp(min=lo, max=hi)\n",
    "\n",
    "    return (u_noisy, sigma, idx) if return_sigma else (u_noisy, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 0. Imports & reproducibility\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import math, random, numpy as np, torch\n",
    "from torch import nn\n",
    "# Basic\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "# torch.set_num_threads(4)\n",
    "\n",
    "# PDEi\n",
    "from utils_pde.utils_pde_2dpoisson import Poisson2D\n",
    "\n",
    "# Viz\n",
    "from utils_tools.utils_result_viz import plot_predictions_2D\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "\n",
    "# Base Mdoels\n",
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "from utils_uqmd.utils_uq_mlp import MLPPINN\n",
    "from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# CP\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "# 9743\n",
    "# 345\n",
    "seed = 345\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1. Ground-truth PDE setup \n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "from utils_pde.utils_pde_allencahn2d import AllenCahn2D\n",
    "\n",
    "# 1) keep the torch-based definition\n",
    "def true_solution(xy):\n",
    "    return torch.sin(math.pi*xy[...,0:1]) * torch.sin(math.pi*xy[...,1:2])\n",
    "\n",
    "domain=((-1.0, 1.0), (-1.0, 1.0))\n",
    "pde = AllenCahn2D(lam=0.05, domain=domain, true_solution=true_solution)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2. Data Generation (Noisy data for training, test, calibration)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "colloc_pt_num = 1024  # Number of collocation points\n",
    "\n",
    "data_noise = 0.05\n",
    "N_train = 300\n",
    "N_test = 2000 # 5000\n",
    "N_calib = 100\n",
    "\n",
    "\n",
    "N_total= N_train+N_test+N_calib\n",
    "\n",
    "X_train, Y_train = pde.data_generation(N_train, data_noise)\n",
    "X_test, Y_test = pde.data_generation(N_test, data_noise)\n",
    "X_calibration, Y_calibration = pde.data_generation(N_calib, data_noise)\n",
    "\n",
    "# Not involved in numerical experiment\n",
    "N_valid = 200\n",
    "X_validation, Y_validation= pde.data_generation(N_valid, data_noise)\n",
    "X_vis, Y_vis = pde.data_generation(N_total, data_noise)\n",
    "\n",
    "# Generating alphas to test\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(n=20, step=0.05)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3. Visualization: Plot ground-truth & noisy data\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def make_dense_grid(domain, N=200):\n",
    "    x = np.linspace(domain[0][0], domain[0][1], N)\n",
    "    y = np.linspace(domain[1][0], domain[1][1], N)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XY_grid = np.stack([X.ravel(), Y.ravel()], axis=-1)\n",
    "    return XY_grid, X, Y\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_truth_and_samples_2D(\n",
    "    X_train, Y_train, grid, U_true_grid, domain,\n",
    "    title=\"Allen-Cahn 2D: ground-truth vs noisy data\"\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    # Show the true solution as a colormap\n",
    "    x = np.linspace(domain[0][0], domain[0][1], U_true_grid.shape[0])\n",
    "    y = np.linspace(domain[1][0], domain[1][1], U_true_grid.shape[1])\n",
    "    im = ax.imshow(\n",
    "        U_true_grid,\n",
    "        extent=(domain[0][0], domain[0][1], domain[1][0], domain[1][1]),\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        alpha=0.8,\n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    # Overlay noisy training points\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], c=Y_train, edgecolor='k', cmap='viridis', s=18, label=\"Noisy samples\")\n",
    "    plt.colorbar(im, ax=ax, label=\"u(x, y)\")\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# 4) plot again\n",
    "grid_test, X_mesh, Y_mesh = make_dense_grid(domain, 500)\n",
    "grid_test_torch = torch.tensor(grid_test, dtype=torch.float32)\n",
    "U_true_grid = true_solution(grid_test_torch).numpy().reshape(X_mesh.shape)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Defining Testing\n",
    "# --------------------------------------------\n",
    "n_grid = 500\n",
    "g  = torch.Generator().manual_seed(seed)\n",
    "\n",
    "\n",
    "# Define printing grid\n",
    "grid_test, u = pde.solution_field_on_grid(n_grid, source=\"true\", flatten=True)\n",
    "u_noisy, sigma, id_grid = add_gaussian_noise_xy(\n",
    "    grid_test, u,\n",
    "    centers=[(-0.5, -0.5)], radii=0.3, sigmas=[0.55],\n",
    "    base_sigma=0.05, combine=\"quadrature\",\n",
    "    return_sigma=True,\n",
    "    l_shape=dict(corner=(0.3, 0.3), lengths=(0.6, 0.6), thickness=0.1, orientation=\"NE\", sigma=0.55),\n",
    "    edge_tau=0.1\n",
    ")\n",
    "\n",
    "Y_train_clean = Y_train.clone()\n",
    "Y_test_clean  = Y_test.clone()\n",
    "Y_cal_clean   = Y_calibration.clone()\n",
    "\n",
    "Y_train, sigma_train, id_train = add_gaussian_noise_xy(\n",
    "    X_train, Y_train_clean,\n",
    "    centers=[(-0.5, -0.5)], radii=0.3, sigmas=[0.55],\n",
    "    base_sigma=0.00, combine=\"quadrature\",\n",
    "    return_sigma=True,\n",
    "    l_shape=dict(corner=(0.3, 0.3), lengths=(0.6, 0.6), thickness=0.1, orientation=\"NE\", sigma=0.55),\n",
    "    edge_tau=0.1\n",
    ")\n",
    "Y_test, sigma_test, id_test = add_gaussian_noise_xy(\n",
    "    X_test, Y_test_clean,\n",
    "    centers=[(-0.5, -0.5)], radii=0.3, sigmas=[0.55],\n",
    "    base_sigma=0.00, combine=\"quadrature\",\n",
    "    return_sigma=True,\n",
    "    l_shape=dict(corner=(0.3, 0.3), lengths=(0.6, 0.6), thickness=0.1, orientation=\"NE\", sigma=0.55),\n",
    "    edge_tau=0.1\n",
    ")\n",
    "Y_calibration, sigma_calibration, id_calibration = add_gaussian_noise_xy(\n",
    "    X_calibration, Y_cal_clean,\n",
    "    centers=[(-0.5, -0.5)], radii=0.3, sigmas=[0.55],\n",
    "    base_sigma=0.00, combine=\"quadrature\",\n",
    "    return_sigma=True,\n",
    "    l_shape=dict(corner=(0.3, 0.3), lengths=(0.6, 0.6), thickness=0.1, orientation=\"NE\", sigma=0.55),\n",
    "    edge_tau=0.1\n",
    ")\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_truth_and_samples_2D,\n",
    "    save_dir=\"2D_AllenCahn\", prefix=\"2D_AllenCahn_data\",\n",
    ")(\n",
    "    X_test, Y_test, grid_test, U_true_grid, domain,\n",
    "    title=\"Allen-Cahn 2D: ground-truth vs noisy data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2471a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from typing import Sequence, Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def plot_metrics_table(\n",
    "    X_test: torch.Tensor,\n",
    "    cp_uncal_predset,\n",
    "    cp_cal_predset,\n",
    "    true_solution,\n",
    "    df1: pd.DataFrame,\n",
    "    df2: pd.DataFrame,\n",
    "    df1_name: str=\"Uncalibrated\",\n",
    "    df2_name: str=\"Calibrated\",\n",
    "    title: str = \"\",\n",
    "    main_title: str | None = None,\n",
    "    X_vis=None, Y_vis=None,\n",
    "    alpha_level: float = 0.05,\n",
    "    figsize: tuple = (9, 2.5),\n",
    "    max_digits_display = lambda x: f\"{x:.4g}\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Display a side-by-side metrics comparison (table) for the uncalibrated and\n",
    "    calibrated models at a single alpha level.\n",
    "    \"\"\"\n",
    "    # Compute the coverage deviation using mae\n",
    "    def prepare_coverage_data(df):\n",
    "        expected = 1 - df[\"alpha\"]\n",
    "        empirical = df[\"coverage\"]\n",
    "        exp_full = pd.concat([pd.Series([0.0]), expected, pd.Series([1.0])], ignore_index=True)\n",
    "        emp_full = pd.concat([pd.Series([0.0]), empirical, pd.Series([1.0])], ignore_index=True)\n",
    "        sort_idx = exp_full.argsort()\n",
    "        exp_sorted, emp_sorted = exp_full[sort_idx], emp_full[sort_idx]\n",
    "        return exp_sorted.to_numpy(), emp_sorted.to_numpy()\n",
    "\n",
    "    def coverage_deviation(exp, emp, how=\"mae\"):\n",
    "        diff = np.abs(emp - exp)\n",
    "        if   how == \"mae\":  return diff.mean()\n",
    "        elif how == \"rmse\": return np.sqrt((diff**2).mean())\n",
    "        elif how == \"max\":  return diff.max()\n",
    "        else:\n",
    "            raise ValueError(\"metric must be 'mae', 'rmse', or 'max'\")\n",
    "\n",
    "    exp1, emp1 = prepare_coverage_data(df1)\n",
    "    exp2, emp2 = prepare_coverage_data(df2)\n",
    "    dev1 = coverage_deviation(exp1, emp1)  # Using the default metrics\n",
    "    dev2 = coverage_deviation(exp2, emp2)  # Using the default metrics\n",
    "    print(f\"Uncal dev:{dev1}\")\n",
    "    print(f\"Cal dev:{dev2}\")\n",
    "    alpha_level_upper = alpha_level + 1e-3\n",
    "    alpha_level_lower = alpha_level - 1e-3\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Slice the two rows â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    row_uncal = df1.loc[(df1[\"alpha\"] <= alpha_level_upper) & \n",
    "                           (df1[\"alpha\"] >= alpha_level_lower)].copy()\n",
    "    row_uncal[\"model\"] = df1_name\n",
    "    row_uncal[\"expected coverage\"] = (1 - row_uncal[\"alpha\"])\n",
    "    row_uncal[\"mean coverage deviation\"] = \"{:.4f}\".format(dev1)\n",
    "    row_uncal[\"coverage\"] = (row_uncal[\"coverage\"]).map(\"{:.2f}\".format)\n",
    "\n",
    "    row_cal = df2.loc[(df2[\"alpha\"] <= alpha_level_upper) & \n",
    "                        (df2[\"alpha\"] >= alpha_level_lower)].copy()\n",
    "    row_cal[\"model\"] = df2_name\n",
    "    row_cal[\"expected coverage\"] = (1- row_cal[\"alpha\"])\n",
    "    row_cal[\"mean coverage deviation\"] = \"{:.4f}\".format(dev2)\n",
    "    row_cal[\"coverage\"] = (row_cal[\"coverage\"]).map(\"{:.2f}\".format)\n",
    "\n",
    "    if row_uncal.empty or row_cal.empty:\n",
    "        raise ValueError(f\"alpha={alpha_level} not found in both data frames.\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Stack & tidy up â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    rows = pd.concat([row_uncal, row_cal], axis=0).reset_index(drop=True)\n",
    "    rows = rows.rename(columns={\"coverage\": \"actual coverage\"})\n",
    "    # Get all columns except 'model' for the selection\n",
    "    other_cols = [c for c in rows.columns if c != \"model\"]\n",
    "    rows = rows.loc[:, [\"model\"] + other_cols]\n",
    "\n",
    "    \n",
    "    # nice ordering: model | expected alpha | true alpha | <metricsâ€¦>\n",
    "    metric_cols = [c for c in rows.columns if c not in (\"model\", \"expected coverage\", \"actual coverage\", \"mean coverage deviation\", \"sharpness\")]\n",
    "    rows = rows[[\"model\", \"expected coverage\", \"actual coverage\", \"mean coverage deviation\", \"sharpness\"]]\n",
    "    \n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2.5. Format numeric values â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Format all numeric columns to 4 decimal places (excluding 'model' column)\n",
    "    for col in rows.columns:\n",
    "        if pd.api.types.is_numeric_dtype(rows[col]):\n",
    "            rows[col] = rows[col].apply(max_digits_display)  # .4g gives up to 4 significant \n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Plot as table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=rows.values,\n",
    "        colLabels=rows.columns,\n",
    "        loc=\"center\",\n",
    "        cellLoc=\"center\",\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.25)\n",
    "\n",
    "    if main_title is not None:\n",
    "        plt.title(main_title, pad=20, fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235aa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_noise = estimate_true_error_local_max(grid_test, u_noisy, nghd_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905398a9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb55212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "# Define color map\n",
    "colors = [\"#2989ff\",\"#ffffff\", \"#ff424f\"]\n",
    "my_cmap = mcolors.LinearSegmentedColormap.from_list(\"my_cmap\", colors)\n",
    "\n",
    "colors = [\"#8c52ff\",\"#ffffff\", \"#ff66c4\"]\n",
    "my_cmap_2 = mcolors.LinearSegmentedColormap.from_list(\"my_cmap\", colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaef2a0",
   "metadata": {},
   "source": [
    "# Feature Distance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b518c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# Base-Model Instance\n",
    "model_args = {\n",
    "    \"pde_class\":pde,\n",
    "    \"input_dim\":2,\n",
    "    \"hidden_dims\":[16, 32, 64, 64, 64, 32, 16], \n",
    "    \"output_dim\":1,\n",
    "}\n",
    "raw_heuristic = \"feature\"\n",
    "# CP-Model\n",
    "k=30\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":dist_pinn\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"heuristic_u\":raw_heuristic,\n",
    "    \"n_samples\":k\n",
    "}\n",
    "\n",
    "dist_feat_pinn = DistanceUQPINN(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "# Training\n",
    "fit_args = dict(\n",
    "    coloc_pt_num=colloc_pt_num, \n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=4500,\n",
    "    Î»_pde=1.0, Î»_ic=5.0, Î»_data=1.0,\n",
    "    lr=1e-3, stop_schedule=20000\n",
    ")\n",
    "baseline_loss_dict = dist_feat_pinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# Test the model performance\n",
    "baseline_data_loss = dist_feat_pinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# Predicting\n",
    "baseline_pred_kwargs = dict(\n",
    "    n_samples=k,\n",
    "    heuristic_u=\"feature\"\n",
    ")\n",
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5b081",
   "metadata": {},
   "source": [
    "# CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ffeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model\n",
    "dist_feat_pinn_cp = CP(dist_feat_pinn)\n",
    "\n",
    "# Predicting\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"feature\",  # Change this based on cp\n",
    "        \"k\":k\n",
    "}\n",
    "\n",
    "dist_feat_pinn_cp_cal_predset = dist_feat_pinn_cp.predict(\n",
    "        alpha=alpha, X_test=grid_test,\n",
    "        **cp_pred_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75710f80",
   "metadata": {},
   "source": [
    "# Local CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model (Adaptive)\n",
    "\n",
    "# CP Model (Adaptive)\n",
    "from utils_extension.utils_uq_adapcp import AdaptiveCP_f, adaptive_cp_test_uncertainties_grid\n",
    "training_kwargs={\"step_size\":5000, \"gamma\":0.5}\n",
    "quantile_net_config={\n",
    "    \"conf_nn_hidden_layers\":(16, 32, 64, 64,64, 64, 64, 32, 16),\n",
    "    \"conf_nn_lr\":1.7e-4,  # 2, 1\n",
    "    \"conf_nn_epochs\":24000,\n",
    "    \"training_kwargs\":training_kwargs,\n",
    "    \"quant_seed\":seed\n",
    "}\n",
    "adap_kwarg={\n",
    "    \"alpha\":alpha,\n",
    "    \"heuristic\":raw_heuristic,\n",
    "    **quantile_net_config\n",
    "}\n",
    "\n",
    "adap_cp = AdaptiveCP_f(dist_feat_pinn, **adap_kwarg)\n",
    "adp_cp_cal_predset = adap_cp.predict(\n",
    "    alpha=alpha, X_test=grid_test, X_train=X_train, Y_train=Y_train,\n",
    "    X_cal=X_calibration, Y_cal=Y_calibration, k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5aca1",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02869c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_comparison_with_coverage_error_compare(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    y_tick_step=0.5,\n",
    "    grid_size=500\n",
    ")\n",
    "\n",
    "# df1=cp_df_local_smooth\n",
    "# df2=adap_df_local_smooth\n",
    "# cp_df_local, #<--\n",
    "# adap_df_local, #<--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eead5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_tuning import save_plot\n",
    "\n",
    "save_plot(\n",
    "    plot_2D_comparison_with_coverage_error_compare,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"2oddshap\"\n",
    ")(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    y_tick_step=0.5,\n",
    "    grid_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbc2c9c",
   "metadata": {},
   "source": [
    "# Test across the alpha grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf3baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid_2d_ac, cp_test_uncertainties_in_noisy_region\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": dist_feat_pinn_cp,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": dist_feat_pinn,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k,\n",
    "    **quantile_net_config\n",
    "}\n",
    "cp_df_local = cp_test_uncertainties_in_noisy_region(**cp_testing_args)\n",
    "adap_df_local = adaptive_cp_test_uncertainties_grid_2d_ac(**adapcp_testing_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_table(None,None,None,None,cp_df_local,adap_df_local,\"CP\" ,\"Adaptive CP\", alpha_level=0.05, \n",
    "  main_title=\"Local Metrics\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98badc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Metrics\n",
    "\n",
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid, cp_test_uncertainties_in_noisy_region\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": dist_feat_pinn_cp,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": dist_feat_pinn,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k,\n",
    "    **quantile_net_config\n",
    "}\n",
    "cp_df_global = cp_test_uncertainties(**cp_testing_args)\n",
    "adap_df_global = adaptive_cp_test_uncertainties_grid_2d_ac(**adapcp_testing_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58454b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=cp_df_global\n",
    "df2=adap_df_global\n",
    "df1_name=\"CP\" \n",
    "df2_name=\"Adaptive CP\"\n",
    "\n",
    "plot_metrics_table(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Global Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4b0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_single(\n",
    "    name_dfpair,\n",
    "    *,\n",
    "    labels=(\"CP\", \"Local CP\"),\n",
    "    figsize=(7, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=28,\n",
    "    float_label=\"$x \\in \\{x:c=(0,0), r=0.2\\}$\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single coverage curve plot (no subplots).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_dfpair : tuple\n",
    "        (name, df_uncal, df_cal), where each df has 'alpha' and 'coverage' columns.\n",
    "    labels : tuple(str, str)\n",
    "        Legend labels for the two curves (uncal vs cal).\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    suptitle : str | None\n",
    "        Optional overall figure title.\n",
    "    model_title_size : int\n",
    "        Title fontsize for the subplot.\n",
    "    float_label : tuple(str, str)\n",
    "        Floating labels to place at top-left corner of the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    name, df_uncal, df_cal = name_dfpair\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    exp1, emp1 = _prep(df_uncal)\n",
    "    exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "    plt.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\",\n",
    "                     ms=16, lw=5, label=labels[1])\n",
    "    plt.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "                     ms=22, lw=5, label=labels[0])\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "    # # floating label\n",
    "    # if float_label[0]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.98, float_label[0],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=22, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # if float_label[1]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.90, float_label[1],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=16, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # plt.text(\n",
    "    #         0.02, 0.98, \"Global\",\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=28, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    plt.text(\n",
    "            0.02, 0.98, float_label,\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=30, fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Expected Coverage (1 âˆ’ Î±)\", fontsize=23)\n",
    "    # plt.ylabel(\"Empirical Coverage\", fontsize=18)\n",
    "    # plt.title(name, fontsize=model_title_size, fontweight=\"bold\")\n",
    "    plt.margins(x=0.02, y=0.02)\n",
    "    plt.yticks([])\n",
    "    # plt.xticks([])\n",
    "    # plt.legend(loc=\"lower right\", fontsize=14, frameon=True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.tick_params(axis='both', labelsize=17)\n",
    "    return plt\n",
    "\n",
    "\n",
    "pairs = (\"Scenario B\", cp_df_global,    adap_df_global)\n",
    "\n",
    "\n",
    "plot_coverage_single(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in [-1, 1]^2$\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_single,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"cov_C_global\"\n",
    ")(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in [-1, 1]^2$\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c0f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_single(\n",
    "    name_dfpair,\n",
    "    *,\n",
    "    labels=(\"CP\", \"Local CP\"),\n",
    "    figsize=(7, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=35,\n",
    "    float_label=\"$x \\in \\{x:c=(0,0), r=0.2\\}$\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single coverage curve plot (no subplots).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_dfpair : tuple\n",
    "        (name, df_uncal, df_cal), where each df has 'alpha' and 'coverage' columns.\n",
    "    labels : tuple(str, str)\n",
    "        Legend labels for the two curves (uncal vs cal).\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    suptitle : str | None\n",
    "        Optional overall figure title.\n",
    "    model_title_size : int\n",
    "        Title fontsize for the subplot.\n",
    "    float_label : tuple(str, str)\n",
    "        Floating labels to place at top-left corner of the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    name, df_uncal, df_cal = name_dfpair\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    exp1, emp1 = _prep(df_uncal)\n",
    "    exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "    plt.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\",\n",
    "                     ms=16, lw=5, label=labels[1])\n",
    "    plt.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "                     ms=22, lw=5, label=labels[0])\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "    # # floating label\n",
    "    # if float_label[0]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.98, float_label[0],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=22, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # if float_label[1]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.90, float_label[1],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=16, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # plt.text(\n",
    "    #         0.02, 0.98, \"Local\",\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=28, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    plt.text(\n",
    "            0.02, 0.98, float_label,\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=30, fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "\n",
    "    # plt.xlabel(\"Expected Coverage (1 âˆ’ Î±)\", fontsize=23)\n",
    "    # plt.ylabel(\"Empirical Coverage\", fontsize=18)\n",
    "    plt.title(name, fontsize=model_title_size, fontweight=\"bold\")\n",
    "    plt.margins(x=0.02, y=0.02)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    # plt.legend(loc=\"lower right\", fontsize=14, frameon=True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.tick_params(axis='both', labelsize=17)\n",
    "    return plt\n",
    "\n",
    "pairs = (\"Scenario C\", cp_df_local,    adap_df_local)\n",
    "\n",
    "\n",
    "plot_coverage_single(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in \\mathrm{Irregular\\ Shapes}$\"\n",
    ")\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_single,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"cov_C_local\"\n",
    ")(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in \\mathrm{Irregular\\ Shapes}$\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d763efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_noise = estimate_true_error_local_max(grid_test, u_noisy, nghd_size=55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b82b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_plot(\n",
    "    plot_2D_comparison_with_coverage_error_compare,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"2lett\"\n",
    ")(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    # noisy_mask=id_grid, \n",
    "    x_tick_step=0.5, y_tick_step=0.5,      # major ticks every 0.1\n",
    "    grid_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19f9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D_comparison_with_coverage_error_compare(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2),\n",
    "    # noisy_mask=id_grid, \n",
    "    x_tick_step=0.5, y_tick_step=0.5,      # major ticks every 0.1\n",
    "    grid_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a4f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
