{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a2d56f",
   "metadata": {},
   "source": [
    "# Plotting Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53755a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_comparison(\n",
    "    df_uncal,\n",
    "    df_cal,\n",
    "    *,\n",
    "    alpha_col: str = \"alpha\",\n",
    "    cov_col: str = \"coverage\",\n",
    "    labels=(\"Before CP\", \"After CP\"),\n",
    "    title: str = \"Coverage Comparison\",\n",
    "    ax=None,\n",
    "    # --- NEW style controls to align with field plots ---\n",
    "    figsize=(6, 5),          # match plot_uq_field default\n",
    "    n_ticks: int = 9,        # number of major ticks on each axis (incl. endpoints)\n",
    "    font_size: int = 12,     # label/title font\n",
    "    tick_size: int = 10,     # tick label size\n",
    "    grid_alpha: float = 0.2, # grid transparency\n",
    "    box_aspect: float = 1.0, # make axes square like your field panels\n",
    "    # --- extras to match your latest styling ---\n",
    "    lw: float = 5.0,         # line width for both curves\n",
    "    ms1: float = 13.0,       # marker size for uncal curve\n",
    "    ms2: float = 20.0,       # marker size for cal curve\n",
    "    pad: float = 0.03,       # extra margin so endpoints are visible\n",
    "    legend_fontsize: int = 14\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot empirical vs expected coverage for two models, styled to align with the 2D field plots.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "\n",
    "    def _prepare(df):\n",
    "        exp = 1.0 - df[alpha_col].to_numpy()\n",
    "        emp = df[cov_col].to_numpy()\n",
    "        # include endpoints for cleaner lines\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        idx = np.argsort(exp)\n",
    "        return exp[idx], emp[idx]\n",
    "\n",
    "    exp1, emp1 = _prepare(df_uncal)\n",
    "    exp2, emp2 = _prepare(df_cal)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "\n",
    "    # Curves + ideal diagonal\n",
    "    ax.plot(exp1, emp1, marker='o', linestyle='-', color=\"#b13c32\",\n",
    "            markerfacecolor=\"#ed8076\", ms=ms1, lw=lw, label=f'{labels[0]}',\n",
    "            clip_on=False)\n",
    "    ax.plot(exp2, emp2, marker='*', linestyle='-', color=\"#3245b1\",\n",
    "            markerfacecolor=\"#6988ef\", ms=ms2, lw=lw, label=f'{labels[1]}',\n",
    "            clip_on=False)\n",
    "    ax.plot([0, 1], [0, 1], '--', color='gray', lw=max(2, lw*0.4), label='Ideal (y=x)',\n",
    "            clip_on=False)\n",
    "\n",
    "    # Limits, ticks, grid to match the field panels\n",
    "    # Use autoscale + margins so endpoints aren't cramped\n",
    "    ax.autoscale(enable=True, tight=False)\n",
    "    ax.margins(x=pad, y=pad)\n",
    "\n",
    "    ax.xaxis.set_major_locator(LinearLocator(n_ticks))\n",
    "    ax.yaxis.set_major_locator(LinearLocator(n_ticks))\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "    # Fonts & sizing consistent with field plots\n",
    "    ax.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=font_size)\n",
    "    ax.set_ylabel(\"Empirical Coverage\", fontsize=font_size)\n",
    "    ax.set_title(title, fontsize=font_size)\n",
    "    ax.tick_params(axis='both', labelsize=tick_size)\n",
    "\n",
    "    # Make the plotting box square (like the imshow panels)\n",
    "    try:\n",
    "        ax.set_box_aspect(box_aspect)  # mpl>=3.3\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Subtle grid\n",
    "    ax.grid(True, alpha=grid_alpha)\n",
    "\n",
    "    ax.legend(loc='lower right', fontsize=legend_fontsize)\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8eb7ca",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12d744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "# PDEi\n",
    "from utils_pde.utils_pde_2dpoisson import Poisson2D\n",
    "\n",
    "# Viz\n",
    "from utils_tools.utils_result_viz import plot_predictions_2D\n",
    "\n",
    "# Base Mdoels\n",
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "from utils_uqmd.utils_uq_mlp import MLPPINN\n",
    "from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# CP\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "\n",
    "# Ensure reproducibility\n",
    "import random, numpy as np, torch\n",
    "seed = 456 # 12345\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Data Noise\n",
    "data_noise = 0.05          # same as your 2-D example\n",
    "\n",
    "# Alpha\n",
    "alpha = 0.05\n",
    "# Generating alphas to test\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas()\n",
    "\n",
    "\n",
    "# Define the 3-D Helmholtz PDE\n",
    "from utils_pde.utils_pde_3dhelmholtz import Helmholtz3D\n",
    "domain = ((0.0, 1.0), (0.0, 1.0), (0.0, 1.0))   # (x0,x1),(y0,y1),(z0,z1)\n",
    "k = math.pi                                     # wave number\n",
    "\n",
    "true_solution = (\n",
    "    lambda xyz: torch.sin(math.pi * xyz[..., 0:1])\n",
    "              * torch.sin(math.pi * xyz[..., 1:2])\n",
    "              * torch.sin(math.pi * xyz[..., 2:3])\n",
    ")\n",
    "\n",
    "pde = Helmholtz3D(k=k, domain=domain, true_solution=true_solution)\n",
    "\n",
    "# Generate training / testing / calibration data\n",
    "(X_train, Y_train)         = pde.data_generation(600, data_noise)\n",
    "(X_test,  Y_test)          = pde.data_generation(200, data_noise)\n",
    "(X_calibration, Y_calibration) = pde.data_generation(200, data_noise)\n",
    "\n",
    "\n",
    "# Not used in experiment, only use to generate different file name\n",
    "(X_validation, Y_validation) = pde.data_generation(400, data_noise)\n",
    "\n",
    "# Number of interior collocation points for the PINN residual\n",
    "colloc_pt_num = 8000\n",
    "\n",
    "# --------------------------------------------\n",
    "# (not important, keeped for function call compatability)\n",
    "# --------------------------------------------\n",
    "n_grid = 10 \n",
    "x = torch.linspace(domain[0][0], domain[0][1], n_grid)\n",
    "y = torch.linspace(domain[1][0], domain[1][1], n_grid)\n",
    "z = torch.linspace(domain[2][0], domain[2][1], n_grid)\n",
    "X, Y, Z = torch.meshgrid(x, y, z, indexing='xy')\n",
    "grid_test = torch.cat([X.reshape(-1, 1), Y.reshape(-1, 1), Z.reshape(-1, 1)], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630adb9f",
   "metadata": {},
   "source": [
    "# Dropout Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b3b3b",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283ed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "\n",
    "# Base Model Instance\n",
    "model_args = dict(\n",
    "    pde_class=pde, \n",
    "    input_dim=3,\n",
    "    hidden_dims=[32, 64, 128, 128, 128, 64, 32], \n",
    "    output_dim=1\n",
    ")\n",
    "baseline_pred_kwargs = {  \n",
    "    \"n_samples\":40\n",
    "}\n",
    "\n",
    "# CP Model\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":\"raw_std\", # Change base on if the baseline cp\n",
    "    \"k\":100\n",
    "}\n",
    "\n",
    "cp_pred_kwargs = {\n",
    "    \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "    \"heuristic_u\":\"raw_std\",\n",
    "    \"k\":100\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":do_pinn,   # Change this\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"n_samples\":40\n",
    "}\n",
    "\n",
    "dropout_pinn = DropoutPINN(**model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f7c8d",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d37f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "# Training\n",
    "fit_args = dict(\n",
    "    coloc_pt_num=colloc_pt_num, \n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=5000,\n",
    "    λ_pde=1.0, λ_bc=10.0, λ_data=1.0,\n",
    "    lr=1e-3, stop_schedule=20000\n",
    ")\n",
    "baseline_loss_dict = dropout_pinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# Test the model performance\n",
    "# baseline_data_loss = dropout_pinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# Predicting\n",
    "baseline_pred_kwargs = dict(\n",
    "    n_samples=40\n",
    ")\n",
    "dropout_pinn_uncal_predset = dropout_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f639e93",
   "metadata": {},
   "source": [
    "## Create CP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3c6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model\n",
    "dropout_pinn_cp = CP(dropout_pinn)\n",
    "\n",
    "# Predicting\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"raw_std\",  # Change this based on cp\n",
    "        \"k\":100\n",
    "}\n",
    "\n",
    "dropout_pinn_cp_cal_predset = dropout_pinn_cp.predict(\n",
    "        alpha=alpha, X_test=grid_test,\n",
    "        **cp_pred_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28d2ac",
   "metadata": {},
   "source": [
    "## Plot Coverage Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c93b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Coverage Info\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties, vi_test_uncertainties, do_test_uncertainties, dist_test_uncertainties\n",
    "\n",
    "# Save the plot\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "from utils_tools.utils_result_viz import plot_metrics_table, plot_dual_expected_vs_empirical\n",
    "dropout_pinn_df_uncal = do_test_uncertainties(uqmodel=dropout_pinn, **baseline_testing_args)\n",
    "dropout_pinn_df_cal = cp_test_uncertainties(dropout_pinn_cp, **cp_testing_args)\n",
    "\n",
    "# Save the plot\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "from utils_tools.utils_result_viz import plot_metrics_table\n",
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout\",\n",
    "    # loss=baseline_data_loss\n",
    ")(\n",
    "    grid_test, dropout_pinn_uncal_predset, dropout_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    title=\"2D UQ\", main_title=\"Dropout Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    ")\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_dual_expected_vs_empirical,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout_coverage\",\n",
    "    # loss=baseline_data_loss\n",
    ")(\n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    main_title=\"Dropout Model Coverage Plots\"\n",
    ")\n",
    "\n",
    "\n",
    "plot_dual_expected_vs_empirical(\n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    main_title=\"Dropout Model Coverage Plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8335094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "from utils_tools.utils_result_viz import plot_metrics_table, plot_dual_expected_vs_empirical\n",
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout\",\n",
    "    # loss=baseline_data_loss\n",
    "    )(\n",
    "    grid_test, dropout_pinn_uncal_predset, dropout_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    title=\"2D UQ\", main_title=\"Dropout Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    ")\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_dual_expected_vs_empirical,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout_coverage\",\n",
    "    # loss=baseline_data_loss\n",
    ")(\n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    main_title=\"Dropout Model Coverage Plots\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270010bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout\",\n",
    "    # loss=baseline_data_loss\n",
    ")(\n",
    "    grid_test, dropout_pinn_uncal_predset, dropout_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    title=\"2D UQ\", main_title=\"Dropout Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    ")\n",
    "\n",
    "\n",
    "# save_plot(\n",
    "#     plot_dual_expected_vs_empirical,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"dropout_coverage\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "#     main_title=\"Dropout Model Coverage Plots\"\n",
    "# )\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_comparison,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"dropout_coverage\",\n",
    "    # loss=baseline_data_loss\n",
    ")(\n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c7bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_table(\n",
    "    grid_test, dropout_pinn_uncal_predset, dropout_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "    title=\"2D UQ\", main_title=\"Dropout Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0b82d",
   "metadata": {},
   "source": [
    "# Feature Distance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c32ca",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfabbacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# Base-Model Instance\n",
    "model_args = dict(\n",
    "    pde_class=pde, \n",
    "    input_dim=3,\n",
    "    hidden_dims=[32, 64, 128, 128, 128, 64, 32], \n",
    "    output_dim=1\n",
    ")\n",
    "\n",
    "# CP-Model\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":\"feature\", # Change base on if the baseline cp\n",
    "    \"k\":100\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":dist_pinn\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"heuristic_u\":\"feature\",\n",
    "    \"n_samples\":15, \n",
    "}\n",
    "\n",
    "dist_feat_pinn = DistanceUQPINN(**model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c19f8",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "# Training\n",
    "fit_args = dict(\n",
    "    coloc_pt_num=colloc_pt_num, \n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=5000,\n",
    "    λ_pde=1.0, λ_bc=5.0, λ_data=1.0,\n",
    "    lr=1e-3, stop_schedule=20000\n",
    ")\n",
    "baseline_loss_dict = dist_feat_pinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# Test the model performance\n",
    "baseline_data_loss = dist_feat_pinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# Predicting\n",
    "baseline_pred_kwargs = dict(\n",
    "    n_samples=15, \n",
    "    heuristic_u=\"feature\"\n",
    ")\n",
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98420e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a6c92",
   "metadata": {},
   "source": [
    "## Create CP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c85fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model\n",
    "dist_feat_pinn_cp = CP(dist_feat_pinn)\n",
    "\n",
    "# Predicting\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"feature\",  # Change this based on cp\n",
    "        \"k\":100\n",
    "}\n",
    "\n",
    "dist_feat_pinn_cp_cal_predset = dist_feat_pinn_cp.predict(\n",
    "        alpha=alpha, X_test=grid_test,\n",
    "        **cp_pred_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b107f84e",
   "metadata": {},
   "source": [
    "## Plot Coverage Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8131e980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Coverage Info\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties, vi_test_uncertainties, do_test_uncertainties, dist_test_uncertainties\n",
    "dist_feat_pinn_df_uncal = dist_test_uncertainties(uqmodel=dist_feat_pinn, **baseline_testing_args)\n",
    "dist_feat_pinndf_cal = cp_test_uncertainties(dist_feat_pinn_cp, **cp_testing_args)\n",
    "\n",
    "# Save the plot\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "from utils_tools.utils_result_viz import plot_metrics_table, plot_dual_expected_vs_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5690b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_comparison(\n",
    "    df_uncal,\n",
    "    df_cal,\n",
    "    *,\n",
    "    labels=(\"Before CP\", \"After CP\"),\n",
    "    title=\"Coverage Comparison\",\n",
    "    ax=None,\n",
    "    figsize=(5.8, 5),  # change this to control figure size when ax is None\n",
    "):\n",
    "    \"\"\"Minimal coverage comparison plot.\"\"\"\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    exp1, emp1 = _prep(df_uncal)\n",
    "    exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure  # use existing figure/axes\n",
    "\n",
    "    # curves + ideal\n",
    "    ax.plot(exp1, emp1, 'o-', color=\"#b13c32\", markerfacecolor=\"#ed8076\", ms=11, lw=5,label=labels[0])\n",
    "    ax.plot(exp2, emp2, '*-', color=\"#3245b1\", markerfacecolor=\"#6988ef\", ms=17, lw=5, label=labels[1])\n",
    "    ax.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "    # limits & labels\n",
    "    ax.autoscale(enable=True, tight=False)\n",
    "    ax.margins(x=0.02, y=0.02)      # tiny padding so endpoints aren’t cramped\n",
    "    ax.set_xlabel(\"Expected Coverage (1 − α)\")\n",
    "    ax.set_ylabel(\"Empirical Coverage\")\n",
    "    # ax.set_title(title)\n",
    "    ax.legend(loc='lower right', fontsize=15)\n",
    "    fig.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224448ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"feature_distance\",\n",
    "    loss=baseline_data_loss\n",
    ")(\n",
    "    grid_test, dist_feat_pinn_uncal_predset, dist_feat_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dist_feat_pinn_df_uncal, dist_feat_pinndf_cal,\n",
    "    title=\"3D UQ\", main_title=\"Feature Distance Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_comparison,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"feature_distance_coverage\",\n",
    "    loss=baseline_data_loss\n",
    ")(\n",
    "    dist_feat_pinn_df_uncal, dist_feat_pinndf_cal, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e9d64b",
   "metadata": {},
   "source": [
    "# Latent Distance Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8ae36a",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd4caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# Base-Model Instance\n",
    "model_args = dict(\n",
    "    pde_class=pde, \n",
    "    input_dim=3,\n",
    "    hidden_dims=[32, 64, 128, 128, 128, 64, 32], \n",
    "    output_dim=1\n",
    ")\n",
    "\n",
    "baseline_pred_kwargs = dict(n_samples=200)\n",
    "\n",
    "\n",
    "# CP-Model\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":\"latent\", # Change base on if the baseline cp\n",
    "    \"k\":100\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":dist_pinn\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"heuristic_u\":\"latent\",\n",
    "    \"n_samples\":10, \n",
    "}\n",
    "\n",
    "dist_lat_pinn = DistanceUQPINN(**model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30acd96",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "# Training\n",
    "fit_args = dict(\n",
    "    coloc_pt_num=colloc_pt_num, \n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=5000,\n",
    "    λ_pde=1.0, λ_bc=5.0, λ_data=1.0,\n",
    "    lr=1e-3, stop_schedule=20000\n",
    ")\n",
    "baseline_loss_dict = dist_lat_pinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# Test the model performance\n",
    "baseline_data_loss = dist_lat_pinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# Predicting\n",
    "baseline_pred_kwargs = dict(\n",
    "    n_samples=10, \n",
    "    heuristic_u=\"latent\"\n",
    ")\n",
    "dist_lat_pinn_uncal_predset = dist_lat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032ad9f",
   "metadata": {},
   "source": [
    "## Create CP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f78be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model\n",
    "dist_lat_pinn_cp = CP(dist_lat_pinn)\n",
    "\n",
    "# Predicting\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"latent\",  # Change this based on cp\n",
    "        \"k\":100\n",
    "}\n",
    "\n",
    "dist_lat_pinn_cp_cal_predset = dist_lat_pinn_cp.predict(\n",
    "        alpha=alpha, X_test=grid_test,\n",
    "        **cp_pred_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e93a4",
   "metadata": {},
   "source": [
    "## Plot Coverage Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b140d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing Coverage Info\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties, vi_test_uncertainties, do_test_uncertainties, dist_test_uncertainties\n",
    "dist_lat_pinn_df_uncal = dist_test_uncertainties(uqmodel=dist_lat_pinn, **baseline_testing_args)\n",
    "dist_lat_pinn_df_cal = cp_test_uncertainties(dist_lat_pinn_cp, **cp_testing_args)\n",
    "\n",
    "# Save the plot\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "from utils_tools.utils_result_viz import plot_metrics_table, plot_dual_expected_vs_empirical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17867612",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"latent_distance\",\n",
    "    loss=baseline_data_loss\n",
    ")(\n",
    "    grid_test, dist_lat_pinn_uncal_predset, dist_lat_pinn_cp_cal_predset, \n",
    "    true_solution, \n",
    "    dist_lat_pinn_df_uncal, dist_lat_pinn_df_cal,\n",
    "    title=\"2D UQ\", main_title=\"Latent Distance Model Metrics\", \n",
    "    X_vis=X_train, Y_vis=Y_train,\n",
    "    df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_comparison,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"lat_distance_cov\",\n",
    "    loss=baseline_data_loss\n",
    ")(\n",
    "    dist_lat_pinn_df_uncal, dist_lat_pinn_df_cal,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1bb3fb",
   "metadata": {},
   "source": [
    "# VI Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdf9505",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88fd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "\n",
    "# # Base Model Instance\n",
    "# model_args = {\n",
    "#     \"pde_class\":pde,\n",
    "#     \"input_dim\":3,\n",
    "#     \"hidden_dims\":[32, 64, 128, 264, 264, 264, 128, 64, 32], \n",
    "#     \"output_dim\":1,\n",
    "#     \"mu_std\" : 0.01, \"rho\" : -6, \"prior_std\" : 1.0, \n",
    "#     \"init_data_noise\" : 1.0, \"learn_data_noise\" : False, \n",
    "#     \"act_func\" : nn.Tanh()\n",
    "# }\n",
    "# baseline_pred_kwargs = {\n",
    "#     \"n_samples\":5000 \n",
    "# }\n",
    "\n",
    "# baseline_testing_args = { \n",
    "#     # \"uqmodel\":vi_model, \n",
    "#     \"alphas\":alphas, \n",
    "#     \"X_test\":X_test, \"Y_test\":Y_test\n",
    "# }\n",
    "\n",
    "# vi_bpinn = VIBPINN(**model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409de93",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7096ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base Model\n",
    "# # Training\n",
    "# fit_args = {\n",
    "#     \"coloc_pt_num\":colloc_pt_num,\n",
    "#     \"X_train\":X_train, \n",
    "#     \"Y_train\":Y_train\n",
    "# }\n",
    "# fit_kwargs_grid = {\n",
    "#     \"epochs\":50000,\n",
    "#     \"λ_pde\":1.0, \"λ_bc\":1.0, \"λ_elbo\":1.0,  \n",
    "#     \"lr\":1e-3,\n",
    "#     \"stop_schedule\":20000,\n",
    "#     \"scheduler_kwargs\":{'step_size': 5500, 'gamma': 0.5}\n",
    "# }\n",
    "# baseline_loss_dict = vi_bpinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# # Test the model performance\n",
    "# baseline_data_loss = vi_bpinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# # Predicting\n",
    "# baseline_pred_kwargs = dict(\n",
    "#     n_samples=20\n",
    "# )\n",
    "# vi_bpinn_uncal_predset = vi_bpinn.predict(alpha, grid_test, \n",
    "#                                    **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba00c76",
   "metadata": {},
   "source": [
    "## Create CP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6518e72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CP Model\n",
    "# vi_bpinn_cp = CP(vi_bpinn)\n",
    "\n",
    "# # CP\n",
    "# cp_pred_kwargs = {\n",
    "#         \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "#         \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "#         \"heuristic_u\":\"raw_std\",\n",
    "#         \"k\":10\n",
    "# }\n",
    "\n",
    "# cp_testing_args = {\n",
    "#         \"alphas\":alphas, \n",
    "#         \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "#         \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "#         \"heuristic_u\":\"raw_std\", # Change base on if the baseline model has its original uq band\n",
    "#         \"k\":10\n",
    "# }\n",
    "\n",
    "# vi_bpinn_cp_cal_predset = vi_bpinn_cp.predict(\n",
    "#         alpha=alpha, X_test=grid_test,\n",
    "#         **cp_pred_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84187800",
   "metadata": {},
   "source": [
    "## Plot Coverage Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Computing Coverage Info\n",
    "# from utils_tools.utils_result_metrics import cp_test_uncertainties, vi_test_uncertainties, do_test_uncertainties, dist_test_uncertainties\n",
    "# vi_bpinn_df_uncal = vi_test_uncertainties(uqmodel=vi_bpinn, **baseline_testing_args)\n",
    "# vi_bpinn_df_cal = cp_test_uncertainties(vi_bpinn_cp, **cp_testing_args)\n",
    "\n",
    "# # Save the plot\n",
    "# from utils_tools.utils_tuning import save_plot\n",
    "# from utils_tools.utils_result_viz import plot_metrics_table\n",
    "# save_plot(\n",
    "#     plot_metrics_table,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"vi_bpinn\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     grid_test, vi_bpinn_uncal_predset, vi_bpinn_cp_cal_predset, \n",
    "#     true_solution, \n",
    "#     vi_bpinn_df_uncal, vi_bpinn_df_cal,\n",
    "#     title=\"2D UQ\", main_title =\"VI Model Metrics\", \n",
    "#     X_vis=X_train, Y_vis=Y_train,\n",
    "#     df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    "# )\n",
    "\n",
    "# from utils_tools.utils_result_viz import plot_dual_expected_vs_empirical\n",
    "# save_plot(\n",
    "#     plot_dual_expected_vs_empirical,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"vi_bpinn_coverage\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     vi_bpinn_df_uncal, vi_bpinn_df_cal,\n",
    "#     main_title = \"VI BPINN Coverage Plots\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_plot(\n",
    "#     plot_metrics_table,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"vi_bpinn\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     grid_test, vi_bpinn_uncal_predset, vi_bpinn_cp_cal_predset, \n",
    "#     true_solution, \n",
    "#     vi_bpinn_df_uncal, vi_bpinn_df_cal,\n",
    "#     title=\"2D UQ\", main_title =\"VI Model Metrics\", \n",
    "#     X_vis=X_train, Y_vis=Y_train,\n",
    "#     df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    "# )\n",
    "\n",
    "# # save_plot(\n",
    "# #     plot_dual_expected_vs_empirical,\n",
    "# #     save_dir=\"3D_Helmholtz\", prefix=\"dropout_coverage\",\n",
    "# #     loss=baseline_data_loss\n",
    "# # )(\n",
    "# #     dropout_pinn_df_uncal, dropout_pinn_df_cal,\n",
    "# #     main_title=\"Dropout Model Coverage Plots\"\n",
    "# # )\n",
    "\n",
    "# save_plot(\n",
    "#     plot_coverage_comparison,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"vi_bpinn_coverage\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     vi_bpinn_df_uncal, vi_bpinn_df_cal,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6972c31d",
   "metadata": {},
   "source": [
    "# HMC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de788885",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c30ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils_uqmd.utils_uq_hmc import HMCBPINN\n",
    "\n",
    "# # Base Model Instance\n",
    "# model_args = dict(\n",
    "#     pde_class=pde, input_dim=3, \n",
    "#     hidden_dims=[32, 64, 128, 264, 264, 264, 128, 64, 32],\n",
    "#     output_dim=1, act_func=nn.Tanh, prior_std=1.0,\n",
    "#     step_size=1e-3, leapfrog_steps=5\n",
    "# )\n",
    "\n",
    "# baseline_testing_args = {\n",
    "#     # \"uqmodel\": hmc_model,\n",
    "#     \"alphas\": alphas,\n",
    "#     \"X_test\": X_test,\n",
    "#     \"Y_test\": Y_test,\n",
    "#     \"n_samples\": 5000\n",
    "# }\n",
    "\n",
    "# baseline_pred_kwargs = {\"n_samples\": 5000}\n",
    "\n",
    "# hmc_bpinn = HMCBPINN(**model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb99997",
   "metadata": {},
   "source": [
    "## Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base Model\n",
    "# # Training\n",
    "# fit_args = {\n",
    "#     \"coloc_pt_num\":colloc_pt_num,\n",
    "#     \"X_train\":X_train, \n",
    "#     \"Y_train\":Y_train\n",
    "# }\n",
    "# fit_kwargs_grid = {\n",
    "#     \"λ_pde\": 1.0,\n",
    "#     \"λ_bc\": 3.0,\n",
    "#     \"λ_data\": 5.0,\n",
    "#     \"epochs\": 5000,\n",
    "#     \"lr\":1e-3,\n",
    "#     \"hmc_samples\": 15000,\n",
    "#     \"brun_in\":5000,\n",
    "#     \"step_size\": 1e-4,\n",
    "#     \"leapfrog_steps\": 13\n",
    "# }\n",
    "# baseline_loss_dict = hmc_bpinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# # Test the model performance\n",
    "# baseline_data_loss = hmc_bpinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "# hmc_bpinn_uncal_predset = hmc_bpinn.predict(\n",
    "#             alpha=alpha, X_test=X_test,\n",
    "#             **baseline_pred_kwargs\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ec6aa6",
   "metadata": {},
   "source": [
    "## Create CP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CP Model\n",
    "# hmc_bpinn_cp = CP(hmc_bpinn)\n",
    "\n",
    "# # CP\n",
    "# cp_pred_kwargs = { \n",
    "#     \"X_train\": X_train, \"Y_train\": Y_train,\n",
    "#     \"X_cal\": X_calibration, \"Y_cal\": Y_calibration,\n",
    "#     \"heuristic_u\": \"raw_std\", \"k\": 100\n",
    "# }\n",
    "\n",
    "# cp_testing_args = {\n",
    "#     \"alphas\":alphas, \n",
    "#     \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "#     \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "#     \"heuristic_u\":\"raw_std\", # Change base on if the baseline model has its original uq band\n",
    "#     \"k\":100\n",
    "# }\n",
    "\n",
    "# hmc_bpinn_cp_cal_predset = hmc_bpinn_cp.predict(\n",
    "#         alpha=alpha, X_test=grid_test,\n",
    "#         **cp_pred_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6159bf",
   "metadata": {},
   "source": [
    "## Plot Coverage Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344189f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Computing Coverage Info\n",
    "# from utils_tools.utils_result_metrics import hmc_test_uncertainties, cp_test_uncertainties, vi_test_uncertainties, do_test_uncertainties, dist_test_uncertainties\n",
    "# hmc_bpinn_df_uncal = hmc_test_uncertainties(uqmodel=hmc_bpinn, **baseline_testing_args)\n",
    "# hmc_bpinn_df_cal = cp_test_uncertainties(hmc_bpinn_cp, **cp_testing_args)\n",
    "\n",
    "# # Save the plot\n",
    "# from utils_tools.utils_tuning import save_plot\n",
    "# from utils_tools.utils_result_viz import plot_metrics_table, plot_dual_expected_vs_empirical\n",
    "# save_plot(\n",
    "#     plot_metrics_table,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"hmc_bpinn\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     grid_test, hmc_bpinn_uncal_predset, hmc_bpinn_cp_cal_predset, \n",
    "#     true_solution, \n",
    "#     hmc_bpinn_df_uncal, hmc_bpinn_df_cal,\n",
    "#     title=\"2D UQ\", main_title=\"HMC Model Metrics\", \n",
    "#     X_vis=X_train, Y_vis=Y_train,\n",
    "#     df1_name=\"Uncalibrated\", df2_name=\"Calibrated\"\n",
    "# )\n",
    "\n",
    "# save_plot(\n",
    "#     plot_dual_expected_vs_empirical,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"hmc_bpinn_coverage\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     hmc_bpinn_df_uncal, hmc_bpinn_df_cal,\n",
    "#     main_title=\"HMC BPINN Coverage Plots\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save_plot(\n",
    "#     plot_coverage_comparison,\n",
    "#     save_dir=\"3D_Helmholtz\", prefix=\"hmc_bpinn_coverage\",\n",
    "#     loss=baseline_data_loss\n",
    "# )(\n",
    "#     hmc_bpinn_df_uncal, hmc_bpinn_df_cal,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd433df",
   "metadata": {},
   "source": [
    "# Coverage Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5deceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_grid_2x2(\n",
    "    named_pairs,\n",
    "    *,\n",
    "    labels=(\"Before CP\", \"After CP\"),\n",
    "    grid_figsize=(14.9, 5),\n",
    "    suptitle=None,\n",
    "    model_title_size=19,\n",
    "):\n",
    "    \"\"\"\n",
    "    named_pairs: list or dict of exactly 4 items like:\n",
    "        [(\"Model A\", df_uncal_A, df_cal_A), ...]\n",
    "        OR {\"Model A\": (df_uncal_A, df_cal_A), ...}\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # --- same prep as in plot_coverage_comparison ---\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    # normalize input\n",
    "    items = list(named_pairs.items()) if isinstance(named_pairs, dict) else list(named_pairs)\n",
    "    # if len(items) != 4:\n",
    "        # raise ValueError(\"Provide exactly 4 (name, df_uncal, df_cal) pairs.\")\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3, figsize=grid_figsize)\n",
    "\n",
    "    i = 0\n",
    "    for ax, (name, df_uncal, df_cal) in zip(axs.ravel(), items):\n",
    "        # --- begin: copied body of plot_coverage_comparison (minimal version) ---\n",
    "        exp1, emp1 = _prep(df_uncal)\n",
    "        exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "        # curves + ideal\n",
    "        ax.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\", ms=11, lw=4, label=labels[0])\n",
    "        ax.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\", ms=17, lw=4, label=labels[1])\n",
    "        ax.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "        i+=1\n",
    "        if i <= 1:\n",
    "            # limits & labels\n",
    "            ax.autoscale(enable=True, tight=False)\n",
    "            ax.margins(x=0.03, y=0.03)      # tiny padding so endpoints aren’t cramped\n",
    "            ax.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=16)\n",
    "            ax.set_ylabel(\"Empirical Coverage\", fontsize=16)\n",
    "            ax.legend(loc='lower right', fontsize=14.5)\n",
    "            # --- end: copied body ---\n",
    "\n",
    "            # subplot title = model name\n",
    "            ax.set_title(name, fontsize=model_title_size)\n",
    "        else:\n",
    "            ax.autoscale(enable=True, tight=False)\n",
    "            ax.margins(x=0.03, y=0.03)      # tiny padding so endpoints aren’t cramped\n",
    "            # ax.legend(loc='upper left', fontsize=13)\n",
    "            ax.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=16)\n",
    "            # --- end: copied body ---\n",
    "            ax.yaxis.set_visible(False)\n",
    "            # subplot title = model name\n",
    "            ax.set_title(name, fontsize=model_title_size)\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=model_title_size + 2)\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    else:\n",
    "        fig.tight_layout()\n",
    "\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6670f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"GD\",     dist_feat_pinn_df_uncal, dist_feat_pinndf_cal),\n",
    "    (\"LD\",    dist_lat_pinn_df_uncal, dist_lat_pinn_df_cal),\n",
    "    (\"Dropout\", dropout_pinn_df_uncal, dropout_pinn_df_cal),\n",
    "]\n",
    "fig, axs = plot_coverage_grid_2x2(pairs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_plot(\n",
    "\n",
    "    plot_coverage_grid_2x2,\n",
    "    save_dir=\"3D_Helmholtz\", prefix=\"coverage_sets\",\n",
    "    loss=baseline_data_loss\n",
    ")(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_grid_1x2(\n",
    "    named_pairs,\n",
    "    *,\n",
    "    labels=(\"After CP\", \"After Local CP\"),\n",
    "    grid_figsize=(16, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=22,\n",
    "    middle_ratio=0.55,              # width of legend column relative to each plot\n",
    "):\n",
    "    \"\"\"\n",
    "    named_pairs: list or dict of exactly 2 items like:\n",
    "        [(\"Model A\", df_uncal_A, df_cal_A), (\"Model B\", df_uncal_B, df_cal_B)]\n",
    "        OR {\"Model A\": (df_uncal_A, df_cal_A), \"Model B\": (df_uncal_B, df_cal_B)}\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    # normalize input\n",
    "    items = list(named_pairs.items()) if isinstance(named_pairs, dict) else list(named_pairs)\n",
    "    if len(items) != 2:\n",
    "        raise ValueError(\"Provide exactly 2 (name, df_uncal, df_cal) pairs.\")\n",
    "\n",
    "    # 1x3 layout: [plot1 | legend | plot2]\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 3,\n",
    "        figsize=grid_figsize,\n",
    "        sharey=True,\n",
    "        gridspec_kw={\"width_ratios\": [1.0, middle_ratio, 1.0]}\n",
    "    )\n",
    "\n",
    "    legend_handles, legend_labels = None, None\n",
    "\n",
    "    for ax_plot, (name, df_uncal, df_cal) in zip([axs[0], axs[2]], items):\n",
    "        exp1, emp1 = _prep(df_uncal)\n",
    "        exp2, emp2 = _prep(df_cal)\n",
    "\n",
    "        ax_plot.plot(exp1, emp1, 'o-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "                     ms=14, lw=5, label=labels[0])\n",
    "        ax_plot.plot(exp2, emp2, '*-', color=\"#3291b1\", markerfacecolor=\"#69b5ef\",\n",
    "                     ms=20, lw=5, label=labels[1])\n",
    "        ax_plot.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "        # collect legend once\n",
    "        if legend_handles is None:\n",
    "            legend_handles, legend_labels = ax_plot.get_legend_handles_labels()\n",
    "\n",
    "        # axis cosmetics\n",
    "        ax_plot.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=18)\n",
    "        ax_plot.autoscale(enable=True, tight=False)\n",
    "        ax_plot.margins(x=0.02, y=0.02)\n",
    "        ax_plot.set_title(name, fontsize=model_title_size)\n",
    "\n",
    "    # Y label only on the left plot\n",
    "    axs[0].set_ylabel(\"Empirical Coverage\", fontsize=18)\n",
    "\n",
    "    # Middle axis: legend only\n",
    "    axs[1].axis(\"off\")\n",
    "    for spine in axs[1].spines.values():\n",
    "        spine.set_visible(False)\n",
    "    # Put the legend centered in the middle axis\n",
    "    axs[1].legend(\n",
    "        legend_handles, legend_labels,\n",
    "        loc=\"center\",\n",
    "        frameon=False,\n",
    "        ncol=3,\n",
    "        fontsize=17\n",
    "    )\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=model_title_size + 2, y=0.98)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    return fig, axs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655943b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"GD\",     dist_feat_pinn_df_uncal, dist_feat_pinndf_cal),\n",
    "    (\"LD\",    dist_lat_pinn_df_uncal, dist_lat_pinn_df_cal),\n",
    "]\n",
    "fig, axs = plot_coverage_grid_1x2(pairs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912cf2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"GD\",     dist_feat_pinn_df_uncal, dist_feat_pinndf_cal),\n",
    "    (\"LD\",    dist_lat_pinn_df_uncal, dist_lat_pinn_df_cal),\n",
    "]\n",
    "fig, axs = plot_coverage_grid_1x2_centered_legend(pairs)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
