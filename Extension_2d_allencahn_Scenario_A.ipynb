{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d47b7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_extension_vis_2d import estimate_true_error_local_max, plot_2D_comparison_with_coverage_error_compare, visualize_selected_points, plot_metrics_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5046df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from typing import Sequence, Literal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "def add_gaussian_noise_xy(  # name kept for drop-in; now soft-step by default\n",
    "    xy: torch.Tensor,                 # (N, 2)\n",
    "    u: torch.Tensor,                  # (N, 1) or (N,)\n",
    "    *,\n",
    "    centers: Sequence[Sequence[float]],\n",
    "    radii: float | Sequence[float] | Sequence[Sequence[float]],\n",
    "    sigmas: float | Sequence[float],\n",
    "    base_sigma: float = 0.0,          # background noise std\n",
    "    index_eps: float = 1e-6,          # threshold above background to count as \"modified\"\n",
    "    generator: torch.Generator | None = None,\n",
    "    clamp: tuple[float, float] | None = None,\n",
    "    return_sigma: bool = False,\n",
    "    combine: Literal[\"sum\", \"max\", \"quadrature\"] = \"sum\",\n",
    "    edge_tau: float = 0.05,           # NEW: softness of the boundary (in normalized radial units)\n",
    "):\n",
    "    \"\"\"\n",
    "    Adds heteroscedastic noise with *soft-step* 'islands':\n",
    "      For each center c_k with radius r_k (or ellipse (rx, ry)),\n",
    "      points get extra noise S_k weighted by a smooth indicator:\n",
    "\n",
    "          w_k(x) = sigmoid( (1 - d_k(x)) / edge_tau ),\n",
    "          d_k(x) = sqrt( ((x - c_k)/r_k)^T ((x - c_k)/r_k) )  (normalized distance)\n",
    "\n",
    "      So w_k ≈ 1 deep inside (d<<1), w_k ≈ 0.5 at the boundary (d=1),\n",
    "      and w_k → 0 smoothly outside.\n",
    "\n",
    "    Aggregation across overlapping regions is controlled by `combine`:\n",
    "      - \"sum\"        : sigma = base_sigma + sum_k S_k * w_k\n",
    "      - \"max\"        : sigma = base_sigma + max_k (S_k * w_k)\n",
    "      - \"quadrature\" : sigma = sqrt(base_sigma^2 + sum_k (S_k^2 * w_k^2))\n",
    "\n",
    "    Returns:\n",
    "        (u_noisy, idx)                 OR\n",
    "        (u_noisy, sigma, idx)          if return_sigma=True\n",
    "      - u_noisy: (N, 1)\n",
    "      - sigma:   (N, 1) (only if return_sigma=True)\n",
    "      - idx:     1D LongTensor where (sigma - base_sigma) > index_eps\n",
    "\n",
    "    Notes:\n",
    "      - `edge_tau` is in normalized radial units (relative to each island’s radius).\n",
    "        As a rough rule, the 10–90% transition width in d is ≈ 4.394 * edge_tau.\n",
    "        Set edge_tau→small (e.g., 0.01) to approach a hard step.\n",
    "    \"\"\"\n",
    "    # --- shape checks / normalize ---\n",
    "    if xy.ndim != 2 or xy.shape[1] != 2:\n",
    "        raise ValueError(\"xy must have shape (N, 2)\")\n",
    "    u = u.reshape(-1, 1)\n",
    "    if xy.shape[0] != u.shape[0]:\n",
    "        raise ValueError(\"xy and u must have the same number of points (N)\")\n",
    "\n",
    "    device, dtype = u.device, u.dtype\n",
    "    XY = xy.to(device=device, dtype=dtype)\n",
    "\n",
    "    # --- centers ---\n",
    "    C = torch.as_tensor(centers, dtype=dtype, device=device).reshape(-1, 2)  # (K,2)\n",
    "    K = C.shape[0]\n",
    "\n",
    "    # Fast path: no centers -> background only\n",
    "    if K == 0:\n",
    "        sigma = torch.full_like(u, float(base_sigma))\n",
    "        noise = torch.normal(mean=torch.zeros_like(u), std=sigma, generator=generator)\n",
    "        u_noisy = u + noise\n",
    "        if clamp is not None:\n",
    "            lo, hi = clamp\n",
    "            u_noisy = u_noisy.clamp(min=lo, max=hi)\n",
    "        idx = torch.zeros(0, dtype=torch.long, device=device)\n",
    "        return (u_noisy, sigma, idx) if return_sigma else (u_noisy, idx)\n",
    "\n",
    "    # --- per-center amplitudes (S) ---\n",
    "    S = (torch.full((K,), float(sigmas), dtype=dtype, device=device)\n",
    "         if isinstance(sigmas, (int, float))\n",
    "         else torch.as_tensor(sigmas, dtype=dtype, device=device).reshape(-1))\n",
    "    if S.numel() != K:\n",
    "        raise ValueError(\"sigmas must be scalar or length == len(centers)\")\n",
    "\n",
    "    # --- radii: scalar, (K,), or (K,2) for anisotropic (rx, ry) ---\n",
    "    R_raw = torch.as_tensor(radii, dtype=dtype, device=device)\n",
    "    if R_raw.ndim == 0:\n",
    "        R_iso = R_raw.expand(K)    # isotropic radius shared by all\n",
    "        R_aniso = None\n",
    "    elif R_raw.ndim == 1:\n",
    "        if R_raw.numel() != K:\n",
    "            raise ValueError(\"radii 1D must have length == len(centers)\")\n",
    "        R_iso = R_raw\n",
    "        R_aniso = None\n",
    "    elif R_raw.ndim == 2 and R_raw.shape == (K, 2):\n",
    "        R_iso = None\n",
    "        R_aniso = R_raw\n",
    "    else:\n",
    "        raise ValueError(\"radii must be scalar, length-K, or shape (K,2) for anisotropic\")\n",
    "\n",
    "        # --- compute normalized squared distance Q and soft weights w ---\n",
    "    diff = XY[:, None, :] - C[None, :, :]          # (N,K,2)\n",
    "    tiny = torch.finfo(dtype).tiny\n",
    "    if R_aniso is None:\n",
    "        R2 = (R_iso.clamp_min(tiny)) ** 2          # (K,)\n",
    "        Q  = (diff.pow(2).sum(dim=2)) / R2[None, :]   # (N,K)\n",
    "    else:\n",
    "        R2 = (R_aniso.clamp_min(tiny)) ** 2        # (K,2)\n",
    "        Q  = (diff.pow(2) / R2[None, :, :]).sum(dim=2)  # (N,K)\n",
    "\n",
    "    d = Q.clamp_min(0).sqrt()\n",
    "    tau = max(float(edge_tau), 1e-12)\n",
    "    w = torch.sigmoid((1.0 - d) / tau).to(dtype)   # (N,K) in (0,1)\n",
    "\n",
    "    # --- aggregate sigma by chosen rule ---\n",
    "    if combine == \"sum\":\n",
    "        add = w * S[None, :]\n",
    "        sigma = add.sum(dim=1, keepdim=True) + float(base_sigma)\n",
    "    elif combine == \"max\":\n",
    "        add = w * S[None, :]\n",
    "        sigma = add.max(dim=1, keepdim=True).values + float(base_sigma)\n",
    "    elif combine == \"quadrature\":\n",
    "        add = (w * S[None, :]) ** 2\n",
    "        sigma = (add.sum(dim=1, keepdim=True) + float(base_sigma) ** 2).sqrt()\n",
    "    else:\n",
    "        raise ValueError(\"combine must be one of: 'sum', 'max', 'quadrature'\")\n",
    "\n",
    "    sigma = sigma.clamp_min(0)\n",
    "\n",
    "    # === NEW: indices strictly inside at least one island (hard mask) ===\n",
    "    # Use Q < 1 (strictly inside). Add a tiny tolerance to avoid boundary picks.\n",
    "    inside = (Q < (1.0 + 2)).any(dim=1)        # (N,)\n",
    "    idx = torch.nonzero(inside, as_tuple=False).squeeze(1)\n",
    "\n",
    "    # --- sample noise & add ---\n",
    "    noise = torch.normal(mean=torch.zeros_like(u), std=sigma, generator=generator)\n",
    "    u_noisy = u + noise\n",
    "    if clamp is not None:\n",
    "        lo, hi = clamp\n",
    "        u_noisy = u_noisy.clamp(min=lo, max=hi)\n",
    "\n",
    "    return (u_noisy, sigma, idx) if return_sigma else (u_noisy, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987c1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 0. Imports & reproducibility\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import math, random, numpy as np, torch\n",
    "from torch import nn\n",
    "# Basic\n",
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "# torch.set_num_threads(4)\n",
    "\n",
    "# PDEi\n",
    "from utils_pde.utils_pde_2dpoisson import Poisson2D\n",
    "\n",
    "# Viz\n",
    "from utils_tools.utils_result_viz import plot_predictions_2D\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "\n",
    "# Base Mdoels\n",
    "from utils_uqmd.utils_uq_dropout import DropoutPINN\n",
    "from utils_uqmd.utils_uq_mlp import MLPPINN\n",
    "from utils_uqmd.utils_uq_vi import VIBPINN\n",
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# CP\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "seed = 259 # HAPPY BIRTHDAY :)\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Ground-truth PDE setup \n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "from utils_pde.utils_pde_allencahn2d import AllenCahn2D\n",
    "\n",
    "# 1) keep the torch-based definition\n",
    "def true_solution(xy):\n",
    "    return torch.sin(math.pi*xy[...,0:1]) * torch.sin(math.pi*xy[...,1:2])\n",
    "\n",
    "domain=((-1.0, 1.0), (-1.0, 1.0))\n",
    "pde = AllenCahn2D(lam=0.05, domain=domain, true_solution=true_solution)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2. Data Generation (Noisy data for training, test, calibration)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "colloc_pt_num = 1024  # Number of collocation points\n",
    "\n",
    "data_noise = 0.05\n",
    "N_train = 300\n",
    "N_test = 2000 # 2000\n",
    "N_calib = 100\n",
    "\n",
    "\n",
    "\n",
    "N_total= N_train+N_test+N_calib\n",
    "\n",
    "X_train, Y_train = pde.data_generation(N_train, data_noise)\n",
    "X_test, Y_test = pde.data_generation(N_test, data_noise)\n",
    "X_calibration, Y_calibration = pde.data_generation(N_calib, data_noise)\n",
    "\n",
    "\n",
    "\n",
    "# Not involved in numerical experiment\n",
    "N_valid = 200\n",
    "X_validation, Y_validation= pde.data_generation(N_valid, data_noise)\n",
    "X_vis, Y_vis = pde.data_generation(N_total, data_noise)\n",
    "\n",
    "# Generating alphas to test\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(n=20, step=0.05)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Visualization: Plot ground-truth & noisy data\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "def make_dense_grid(domain, N=200):\n",
    "    x = np.linspace(domain[0][0], domain[0][1], N)\n",
    "    y = np.linspace(domain[1][0], domain[1][1], N)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    XY_grid = np.stack([X.ravel(), Y.ravel()], axis=-1)\n",
    "    return XY_grid, X, Y\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_truth_and_samples_2D(\n",
    "    X_train, Y_train, grid, U_true_grid, domain,\n",
    "    title=\"Allen-Cahn 2D: ground-truth vs noisy data\"\n",
    "):\n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    # Show the true solution as a colormap\n",
    "    x = np.linspace(domain[0][0], domain[0][1], U_true_grid.shape[0])\n",
    "    y = np.linspace(domain[1][0], domain[1][1], U_true_grid.shape[1])\n",
    "    im = ax.imshow(\n",
    "        U_true_grid,\n",
    "        extent=(domain[0][0], domain[0][1], domain[1][0], domain[1][1]),\n",
    "        origin='lower',\n",
    "        aspect='auto',\n",
    "        alpha=0.8,\n",
    "        cmap='coolwarm'\n",
    "    )\n",
    "    # Overlay noisy training points\n",
    "    ax.scatter(X_train[:,0], X_train[:,1], c=Y_train, edgecolor='k', cmap='viridis', s=18, label=\"Noisy samples\")\n",
    "    plt.colorbar(im, ax=ax, label=\"u(x, y)\")\n",
    "    ax.set_xlabel(\"x\"); ax.set_ylabel(\"y\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# 4) plot again\n",
    "grid_test, X_mesh, Y_mesh = make_dense_grid(domain, 500)\n",
    "grid_test_torch = torch.tensor(grid_test, dtype=torch.float32)\n",
    "U_true_grid = true_solution(grid_test_torch).numpy().reshape(X_mesh.shape)\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Defining Testing\n",
    "# --------------------------------------------\n",
    "n_grid = 500\n",
    "g  = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# Define printing grid\n",
    "grid_test, u = pde.solution_field_on_grid(n_grid, source=\"true\", flatten=True)\n",
    "u_noisy, sigma, id_grid = add_gaussian_noise_xy(\n",
    "    grid_test, u,\n",
    "    centers=[(0.0,0.0)],\n",
    "    radii=[0.2,],\n",
    "    sigmas=[0.4,],\n",
    "    base_sigma=0.05,\n",
    "    combine=\"sum\",\n",
    "    generator=g,\n",
    "    return_sigma=True,\n",
    "    edge_tau=0.2\n",
    ")\n",
    "\n",
    "Y_train_clean = Y_train.clone()\n",
    "Y_test_clean  = Y_test.clone()\n",
    "Y_cal_clean   = Y_calibration.clone()\n",
    "\n",
    "Y_train, sigma_train, id_train = add_gaussian_noise_xy(\n",
    "    X_train, Y_train_clean,\n",
    "    centers=[(0.0,0.0)],\n",
    "    radii=[0.2,],\n",
    "    sigmas=[0.4,],\n",
    "    base_sigma=0.0,\n",
    "    combine=\"sum\",\n",
    "    generator=g,\n",
    "    return_sigma=True,\n",
    "    edge_tau=0.2\n",
    ")\n",
    "Y_test, sigma_test, id_test = add_gaussian_noise_xy(\n",
    "    X_test, Y_test_clean,\n",
    "    centers=[(0.0,0.0)],\n",
    "    radii=[0.2,],\n",
    "    sigmas=[0.4,],\n",
    "    base_sigma=0.0,\n",
    "    combine=\"sum\",\n",
    "    generator=g,\n",
    "    return_sigma=True,\n",
    "    edge_tau=0.2\n",
    ")\n",
    "Y_calibration, sigma_calibration, id_calibration = add_gaussian_noise_xy(\n",
    "    X_calibration, Y_cal_clean,\n",
    "    centers=[(0.0,0.0)],\n",
    "    radii=[0.2,],\n",
    "    sigmas=[0.4,],\n",
    "    base_sigma=0.0,\n",
    "    combine=\"sum\",\n",
    "    generator=g,\n",
    "    return_sigma=True,\n",
    "    edge_tau=0.2\n",
    ")\n",
    "\n",
    "\n",
    "save_plot(\n",
    "    plot_truth_and_samples_2D,\n",
    "    save_dir=\"2D_AllenCahn\", prefix=\"2D_AllenCahn_data\",\n",
    ")(\n",
    "    X_test, Y_test, grid_test, U_true_grid, domain,\n",
    "    title=\"Allen-Cahn 2D: ground-truth vs noisy data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905398a9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb55212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "# Define color map\n",
    "colors = [\"#2989ff\",\"#ffffff\", \"#ff424f\"]\n",
    "my_cmap = mcolors.LinearSegmentedColormap.from_list(\"my_cmap\", colors)\n",
    "\n",
    "colors = [\"#8c52ff\",\"#ffffff\", \"#ff66c4\"]\n",
    "my_cmap_2 = mcolors.LinearSegmentedColormap.from_list(\"my_cmap\", colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaef2a0",
   "metadata": {},
   "source": [
    "# Feature Distance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b518c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "# Base-Model Instance\n",
    "model_args = {\n",
    "    \"pde_class\":pde,\n",
    "    \"input_dim\":2,\n",
    "    \"hidden_dims\":[16, 32, 64, 64, 64, 32, 16], \n",
    "    \"output_dim\":1,\n",
    "}\n",
    "raw_heuristic = \"feature\"\n",
    "# CP-Model\n",
    "k=30 # 30\n",
    "cp_testing_args = {\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "\n",
    "baseline_testing_args = { \n",
    "    # \"uqmodel\":dist_pinn\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test,\n",
    "    \"heuristic_u\":raw_heuristic,\n",
    "    \"n_samples\":k\n",
    "}\n",
    "\n",
    "dist_feat_pinn = DistanceUQPINN(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d074ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Model\n",
    "# Training\n",
    "fit_args = dict(\n",
    "    coloc_pt_num=colloc_pt_num, \n",
    "    X_train=X_train, \n",
    "    Y_train=Y_train\n",
    ")\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=4500,\n",
    "    λ_pde=1.0, λ_ic=5.0, λ_data=1.0,\n",
    "    lr=1e-3, stop_schedule=20000\n",
    ")\n",
    "baseline_loss_dict = dist_feat_pinn.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n",
    "# Test the model performance\n",
    "baseline_data_loss = dist_feat_pinn.data_loss(X_validation, Y_validation)\n",
    "\n",
    "\n",
    "# Predicting\n",
    "baseline_pred_kwargs = dict(\n",
    "    n_samples=k,\n",
    "    heuristic_u=\"feature\"\n",
    ")\n",
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ba18aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_feat_pinn_uncal_predset = dist_feat_pinn.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5b081",
   "metadata": {},
   "source": [
    "# CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ffeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model\n",
    "dist_feat_pinn_cp = CP(dist_feat_pinn)\n",
    "\n",
    "# Predicting\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":\"feature\",  # Change this based on cp\n",
    "        \"k\":k\n",
    "}\n",
    "\n",
    "dist_feat_pinn_cp_cal_predset = dist_feat_pinn_cp.predict(\n",
    "        alpha=alpha, X_test=grid_test,\n",
    "        **cp_pred_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75710f80",
   "metadata": {},
   "source": [
    "# Local CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Model (Adaptive)\n",
    "from utils_extension.utils_uq_adapcp import AdaptiveCP_f, adaptive_cp_test_uncertainties_grid\n",
    "training_kwargs={\"step_size\":5000, \"gamma\":0.5}\n",
    "quantile_net_config={\n",
    "\"conf_nn_hidden_layers\":(16, 32, 64, 64, 64, 32, 16),\n",
    "    \"conf_nn_lr\":1.6e-4,\n",
    "    \"conf_nn_epochs\":14000,\n",
    "    \"training_kwargs\":training_kwargs,\n",
    "    \"quant_seed\":seed\n",
    "}\n",
    "adap_kwarg={\n",
    "    \"alpha\":alpha,\n",
    "    \"heuristic\":raw_heuristic,\n",
    "    **quantile_net_config\n",
    "}\n",
    "\n",
    "adap_cp = AdaptiveCP_f(dist_feat_pinn, **adap_kwarg)\n",
    "adp_cp_cal_predset = adap_cp.predict(\n",
    "    alpha=alpha, X_test=grid_test, X_train=X_train, Y_train=Y_train,\n",
    "    X_cal=X_calibration, Y_cal=Y_calibration, k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48305c77",
   "metadata": {},
   "source": [
    "# Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec50a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_noise = estimate_true_error_local_max(grid_test, u_noisy, nghd_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9645cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_noisy = X_test[id_test]\n",
    "plot_2D_comparison_with_coverage_error_compare(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    y_tick_step=0.5,\n",
    "    grid_size=500\n",
    ")\n",
    "\n",
    "# df1=cp_df_local_smooth\n",
    "# df2=adap_df_local_smooth\n",
    "# cp_df_local, #<--\n",
    "# adap_df_local, #<--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9028b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_noise = estimate_true_error_local_max(grid_test, u_noisy, nghd_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_2D_comparison_with_coverage_error_compare,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"1disc\"\n",
    ")(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    y_tick_step=0.5,\n",
    "    grid_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8bc1f4",
   "metadata": {},
   "source": [
    "# Test across the alpha grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid_2d_ac, cp_test_uncertainties_in_noisy_region\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": dist_feat_pinn_cp,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": dist_feat_pinn,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k,\n",
    "    **quantile_net_config\n",
    "}\n",
    "cp_df_local = cp_test_uncertainties_in_noisy_region(**cp_testing_args)\n",
    "adap_df_local = adaptive_cp_test_uncertainties_grid_2d_ac(**adapcp_testing_args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81bb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics_table(None,None,None,None,cp_df_local,adap_df_local,\"CP\" ,\"Adaptive CP\", alpha_level=0.05, \n",
    "  main_title=\"Local Metrics\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe7d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Metrics\n",
    "\n",
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid, cp_test_uncertainties_in_noisy_region\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": dist_feat_pinn_cp,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": dist_feat_pinn,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":k,\n",
    "    **quantile_net_config\n",
    "}\n",
    "cp_df_global = cp_test_uncertainties(**cp_testing_args)\n",
    "adap_df_global = adaptive_cp_test_uncertainties_grid_2d_ac(**adapcp_testing_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7459a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=cp_df_global\n",
    "df2=adap_df_global\n",
    "df1_name=\"CP\" \n",
    "df2_name=\"Adaptive CP\"\n",
    "\n",
    "plot_metrics_table(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Global Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_single(\n",
    "    name_dfpair,\n",
    "    *,\n",
    "    labels=(\"CP\", \"Local CP\"),\n",
    "    figsize=(7.8, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=28,\n",
    "    float_label=\"$x \\in \\{x:c=(0,0), r=0.2\\}$\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single coverage curve plot (no subplots).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_dfpair : tuple\n",
    "        (name, df_uncal, df_cal), where each df has 'alpha' and 'coverage' columns.\n",
    "    labels : tuple(str, str)\n",
    "        Legend labels for the two curves (uncal vs cal).\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    suptitle : str | None\n",
    "        Optional overall figure title.\n",
    "    model_title_size : int\n",
    "        Title fontsize for the subplot.\n",
    "    float_label : tuple(str, str)\n",
    "        Floating labels to place at top-left corner of the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    name, df_uncal, df_cal = name_dfpair\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    exp1, emp1 = _prep(df_uncal)\n",
    "    exp2, emp2 = _prep(df_cal)\n",
    "    plt.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\",\n",
    "             ms=16, lw=5, label=labels[0])\n",
    "    plt.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "             ms=22, lw=5, label=labels[1])\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "    # # floating label\n",
    "    # if float_label[0]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.98, float_label[0],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=22, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # if float_label[1]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.90, float_label[1],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=16, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # plt.text(\n",
    "    #         0.02, 0.98, \"Global\",\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=28, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    plt.text(\n",
    "            0.02, 0.98, float_label,\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=30, fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "\n",
    "    plt.xlabel(\"Expected Coverage (1 − α)\", fontsize=22)\n",
    "    plt.ylabel(\"Empirical Coverage\", fontsize=23)\n",
    "    # plt.title(name, fontsize=model_title_size, fontweight=\"bold\")\n",
    "    plt.margins(x=0.02, y=0.02)\n",
    "    # plt.yticks([])\n",
    "    # plt.xticks([])\n",
    "    plt.legend(loc=\"lower right\", fontsize=22, frameon=True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.tick_params(axis='both', labelsize=17)\n",
    "    return plt\n",
    "\n",
    "\n",
    "pairs = (\"Scenario A\", cp_df_global,    adap_df_global)\n",
    "\n",
    "\n",
    "plot_coverage_single(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in [-1, 1]^2$\"\n",
    ")\n",
    "save_plot(\n",
    "    plot_coverage_single,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"cov_A_global\"\n",
    ")(\n",
    "    pairs,\n",
    "    float_label=r\"$(x,y) \\in [-1, 1]^2$\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d010717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_single(\n",
    "    name_dfpair,\n",
    "    *,\n",
    "    labels=(\"CP\", \"Local CP\"),\n",
    "    figsize=(7.8, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=35,\n",
    "    float_label=\"$x \\in \\{x:c=(0,0), r=0.2\\}$\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a single coverage curve plot (no subplots).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name_dfpair : tuple\n",
    "        (name, df_uncal, df_cal), where each df has 'alpha' and 'coverage' columns.\n",
    "    labels : tuple(str, str)\n",
    "        Legend labels for the two curves (uncal vs cal).\n",
    "    figsize : tuple\n",
    "        Figure size.\n",
    "    suptitle : str | None\n",
    "        Optional overall figure title.\n",
    "    model_title_size : int\n",
    "        Title fontsize for the subplot.\n",
    "    float_label : tuple(str, str)\n",
    "        Floating labels to place at top-left corner of the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    name, df_uncal, df_cal = name_dfpair\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    exp1, emp1 = _prep(df_uncal)\n",
    "    exp2, emp2 = _prep(df_cal)\n",
    "    plt.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\",\n",
    "             ms=16, lw=5, label=labels[0])\n",
    "    plt.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "             ms=22, lw=5, label=labels[1])\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "    # # floating label\n",
    "    # if float_label[0]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.98, float_label[0],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=22, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # if float_label[1]:\n",
    "    #     plt.text(\n",
    "    #         0.02, 0.90, float_label[1],\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=16, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    # plt.text(\n",
    "    #         0.02, 0.98, \"Local\",\n",
    "    #         transform=plt.gca().transAxes,\n",
    "    #         fontsize=28, fontweight=\"bold\",\n",
    "    #         va=\"top\", ha=\"left\",\n",
    "    #         bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "    #     )\n",
    "    plt.text(\n",
    "            0.02, 0.98, float_label,\n",
    "            transform=plt.gca().transAxes,\n",
    "            fontsize=30, fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "\n",
    "    # plt.xlabel(\"Expected Coverage (1 − α)\", fontsize=23)\n",
    "    plt.ylabel(\"Empirical Coverage\", fontsize=23)\n",
    "    plt.title(name, fontsize=model_title_size, fontweight=\"bold\")\n",
    "    plt.margins(x=0.02, y=0.02)\n",
    "    plt.xticks([])\n",
    "    plt.legend(loc=\"lower right\", fontsize=22, frameon=True)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.tick_params(axis='both', labelsize=17)\n",
    "    return plt\n",
    "\n",
    "pairs = (\"Scenario A\", cp_df_local,    adap_df_local)\n",
    "\n",
    "\n",
    "plot_coverage_single(\n",
    "    pairs,\n",
    "    float_label=r\"$(x, y) \\in \\mathrm{Disc}$\"\n",
    ")\n",
    "\n",
    "save_plot(\n",
    "    plot_coverage_single,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"cov_A_local\"\n",
    ")(\n",
    "    pairs,\n",
    "    float_label=r\"$(x, y) \\in \\mathrm{Disc}$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_est_noise = estimate_true_error_local_max(grid_test, u_noisy, nghd_size=55)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055a2614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_plot(\n",
    "    plot_2D_comparison_with_coverage_error_compare,\n",
    "    save_dir=\"Local_CP_2D\",\n",
    "    prefix=\"1disc\"\n",
    ")(\n",
    "    grid_test,\n",
    "    err_est_noise, # 2*(sigma*1.69),\n",
    "    dist_feat_pinn_uncal_predset,\n",
    "    dist_feat_pinn_cp_cal_predset,\n",
    "    adp_cp_cal_predset, #<--\n",
    "    true_solution, \n",
    "    vlim=(0,2.0),\n",
    "    y_tick_step=0.5,\n",
    "    grid_size=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75ce4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
