{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_1d_intervals_comparison(\n",
    "    X_test,\n",
    "    uncal_interval,                  # (n_lower, n_upper)\n",
    "    cp_intervals,                    # (cp_lower, cp_upper)\n",
    "    true_solution,                   # array OR callable f(X_test)\n",
    "    uncal_interval_label=\"Before CP\",\n",
    "    cal_interval_label=\"After CP\",\n",
    "    t_train=None,\n",
    "    y_train=None,\n",
    "    title=\"PINN Prediction with Conformal & Naïve Intervals\",\n",
    "    figsize=(6, 5),\n",
    "    colors=None,                     # optional dict to override colors by key\n",
    "    alpha_cp=0.7,\n",
    "    alpha_naive=1.0,\n",
    "    dot_size=12,\n",
    "    dot_edge_size=0.7,\n",
    "\n",
    "):\n",
    "    \"\"\"\n",
    "    Matches the styling/semantics of the plotting script:\n",
    "      - CP-band mean is drawn as dashed prediction line\n",
    "      - Legend at lower center with compact handles\n",
    "      - Labeling uses x / u(x), fontsize=14, ylabel rotation=0\n",
    "      - Same color palette and scatter edge styling\n",
    "    \"\"\"\n",
    "\n",
    "    # --- default palette (same constants as your script) ---\n",
    "    palette = {\n",
    "        \"COL_CP\":   \"#f7c5c8\",\n",
    "        \"COL_MEAN\": \"#b13c32\",\n",
    "        \"COL_NAIV\": \"#a3c3ea\",\n",
    "        \"COL_TRUE\": \"#222222\",\n",
    "        \"COL_SCAT\": \"#f6d09f\",\n",
    "        \"COL_EDGE\": \"#222222\",\n",
    "    }\n",
    "    if colors:\n",
    "        palette.update(colors)\n",
    "    COL_NAIV = palette[\"COL_NAIV\"]\n",
    "    COL_MEAN = palette[\"COL_MEAN\"]\n",
    "    COL_CP   = palette[\"COL_CP\"]\n",
    "    COL_TRUE = palette[\"COL_TRUE\"]\n",
    "    COL_SCAT = palette[\"COL_SCAT\"]\n",
    "    COL_EDGE = palette[\"COL_EDGE\"]\n",
    "\n",
    "    # --- evaluate truth if callable ---\n",
    "    if callable(true_solution):\n",
    "        true_vals = np.asarray(true_solution(X_test)).ravel()\n",
    "    else:\n",
    "        true_vals = np.asarray(true_solution).ravel()\n",
    "\n",
    "    # --- to 1D arrays ---\n",
    "    x = np.asarray(X_test).ravel()\n",
    "    n_lower, n_upper = [np.asarray(a).ravel() for a in uncal_interval]\n",
    "    cp_lower, cp_upper = [np.asarray(a).ravel() for a in cp_intervals]\n",
    "\n",
    "    # CP mean (to match your script)\n",
    "    pred_mean = (cp_lower + cp_upper) / 2.0\n",
    "\n",
    "    # --- plot ---\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # wide -> narrow bands first for nicer layering\n",
    "    ax.fill_between(x, n_lower, n_upper, color=COL_NAIV, alpha=alpha_naive,\n",
    "                    label=uncal_interval_label, zorder=1)\n",
    "    ax.fill_between(x, cp_lower, cp_upper, color=COL_CP, alpha=alpha_cp,\n",
    "                    label=cal_interval_label, zorder=2)\n",
    "\n",
    "    # mean + truth\n",
    "    ax.plot(x, pred_mean, ls=\"--\", lw=2.0, color=COL_MEAN,\n",
    "            label=r\"Prediction\", zorder=4)\n",
    "    ax.plot(x, true_vals, lw=2.4, color=COL_TRUE,\n",
    "            label=r\"True\", zorder=3)\n",
    "\n",
    "    # training data (optional)\n",
    "    if t_train is not None and y_train is not None:\n",
    "        ax.scatter(np.asarray(t_train).ravel(), np.asarray(y_train).ravel(),\n",
    "                   s=dot_size, facecolor=COL_SCAT, edgecolors=COL_EDGE,\n",
    "                   linewidth=dot_edge_size, label=\"Data\", zorder=5)\n",
    "\n",
    "    # labels to match script\n",
    "    ax.set_xlabel(r\"$x$\", fontsize=13)\n",
    "    ax.set_ylabel(r\"$u$\", fontsize=13, rotation=90)\n",
    "\n",
    "    # layout/styling to match script\n",
    "    ax.margins(x=0)\n",
    "    ax.legend(loc=\"upper right\", handlelength=1.6, borderpad=0.6)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aeca72",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf08a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 0. Imports & reproducibility\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import math, random, numpy as np, torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from utils_tools.utils_tuning import save_plot\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "seed = 95\n",
    "random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1. Ground-truth PDE setup \n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "from utils_pde.utils_pde_damposcillation import DampedOscillator1D  \n",
    "\n",
    "ζ      = 0.05                       # damping ratio\n",
    "ω      = 2 * math.pi * 1.0          # natural frequency (1 Hz)\n",
    "ω_d    = ω * math.sqrt(1 - ζ**2)    # damped natural frequency\n",
    "u0, v0 = 1.0, 0.0                   # initial displacement & velocity\n",
    "\n",
    "forcing_func  = lambda t: 0.0 * t   # zero external force\n",
    "\n",
    "true_solution = lambda t: (\n",
    "    np.exp(-ζ * ω * t) *\n",
    "    (u0 * np.cos(ω_d * t) + (v0 + ζ * ω * u0) / ω_d * np.sin(ω_d * t))\n",
    ")\n",
    "\n",
    "domain = (0.0, 5.0)                 # simulate 10 s\n",
    "\n",
    "pde = DampedOscillator1D(\n",
    "    zeta=ζ, omega=ω, forcing_func=forcing_func,\n",
    "    init_cond=(u0, v0), domain=domain, true_solution=true_solution\n",
    ")\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3. Training / calibration / test data\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "x_colloc_num = 200\n",
    "\n",
    "data_noise = 0.05\n",
    "(X_train, Y_train)         = pde.data_generation(300, data_noise)\n",
    "(X_test, Y_test)           = pde.data_generation(1000, data_noise)\n",
    "\n",
    "\n",
    "# Not involved in numerical experiment\n",
    "(X_calibration, Y_calibration) = pde.data_generation(150, data_noise)\n",
    "# Dense grid for nice plotting or other stuff, unrelated to the numerical experiment \n",
    "(X_vis, Y_vis) = pde.data_generation(400, data_noise)\n",
    "\n",
    "\n",
    "\n",
    "# Collocation points in (0,5)\n",
    "x_collocation = torch.linspace(*domain, steps=x_colloc_num).view(-1, 1)\n",
    "x_collocation = x_collocation[(x_collocation > domain[0]) & (x_collocation < domain[1])].view(-1, 1)\n",
    "grid_test = torch.linspace(*domain, 3000).unsqueeze(1)\n",
    "\n",
    "# Visualize the graph\n",
    "from utils_tools.utils_result_viz import plot_truth_and_samples_1D\n",
    "plot_truth_and_samples_1D(\n",
    "    *domain,\n",
    "    X_train   = X_train,\n",
    "    Y_train   = Y_train,\n",
    "    true_solution=true_solution,\n",
    "    x_colloc = x_collocation,\n",
    "    title     = \"Underdamped oscillator: ground-truth vs noisy data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6512be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_truth_and_samples_1D(\n",
    "    *domain,\n",
    "    X_train   = X_calibration,\n",
    "    Y_train   = Y_calibration,\n",
    "    true_solution=true_solution,\n",
    "    x_colloc = x_collocation,\n",
    "    title     = \"Underdamped oscillator: ground-truth vs noisy data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70484b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def add_heteroscedastic_noise_islands(\n",
    "    X, Y_clean,\n",
    "    *,\n",
    "    centers=(1, 2, 3),\n",
    "    widths=(0.2, 0.2, 0.2),\n",
    "    bump=0.3,\n",
    "    baseline=0.0,\n",
    "    seed=None,\n",
    "    return_sigma=False,\n",
    "    return_indices=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Add heteroscedastic Gaussian noise in local 'islands' (zero outside [c-w, c+w]).\n",
    "\n",
    "    Returns (depending on flags, in this exact order):\n",
    "        noisy_idx (LongTensor, 1D)  if return_indices=True\n",
    "        Y_noisy   (Tensor, like Y_clean)\n",
    "        sigma     (Tensor, like X)  if return_sigma=True\n",
    "    \"\"\"\n",
    "    assert X.ndim == 2 and X.shape[1] == 1, \"X must be (N,1)\"\n",
    "    assert X.device == Y_clean.device, \"X and Y_clean must be on the same device\"\n",
    "    device = X.device\n",
    "\n",
    "    x = X\n",
    "    sigma = torch.full_like(x, fill_value=baseline)\n",
    "    inside_mask = torch.zeros_like(x, dtype=torch.bool)\n",
    "\n",
    "    for c, w in zip(centers, widths):\n",
    "        phi = torch.exp(-0.5 * ((x - c) / (w + 1e-12))**2)\n",
    "        box = (x >= c - w) & (x <= c + w)     # hard cutoff\n",
    "        phi = phi * box\n",
    "        sigma = sigma + bump * phi\n",
    "        inside_mask |= box\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(int(seed))\n",
    "\n",
    "    z = torch.randn_like(Y_clean)\n",
    "    Y_noisy = Y_clean + sigma * z\n",
    "\n",
    "    if return_indices:\n",
    "        noisy_idx = torch.nonzero(inside_mask.squeeze(-1), as_tuple=True)[0].to(device=device, dtype=torch.long)\n",
    "\n",
    "    if return_sigma and return_indices:\n",
    "        return noisy_idx, Y_noisy, sigma\n",
    "    elif return_sigma:\n",
    "        return Y_noisy, sigma\n",
    "    elif return_indices:\n",
    "        return noisy_idx, Y_noisy\n",
    "    else:\n",
    "        return Y_noisy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab41058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True outputs without noise\n",
    "Y_train_clean = Y_train.clone()\n",
    "Y_test_clean  = Y_test.clone()\n",
    "Y_cal_clean   = Y_calibration.clone()\n",
    "Y_vis_clean   = Y_vis.clone()\n",
    "\n",
    "# Add heteroscedastic noise\n",
    "id_train, Y_train        = add_heteroscedastic_noise_islands(X_train, Y_train_clean)\n",
    "id_test, Y_test         = add_heteroscedastic_noise_islands(X_test,  Y_test_clean)\n",
    "id_calibration, Y_calibration  = add_heteroscedastic_noise_islands(X_calibration, Y_cal_clean)\n",
    "id_vis, Y_vis  = add_heteroscedastic_noise_islands(X_vis, Y_vis_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891302fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from utils_tools.utils_result_viz import plot_truth_and_samples_1D\n",
    "save_plot(\n",
    "    plot_truth_and_samples_1D,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"heteroscedasticity_data\"\n",
    ")(\n",
    "    *domain,\n",
    "    X_train   = X_train,\n",
    "    Y_train   = Y_train,\n",
    "    true_solution=true_solution,\n",
    "    x_colloc = x_collocation,\n",
    "    title     = \"Underdamped oscillator: ground-truth vs noisy data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07242bba",
   "metadata": {},
   "source": [
    "# Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10ff594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UQ Model\n",
    "from utils_uqmd.utils_uq_distance import DistanceUQPINN\n",
    "\n",
    "model_args = {\n",
    "    \"pde_class\":pde,\n",
    "    \"input_dim\":1,\n",
    "    \"hidden_dims\":[16, 32, 64, 128, 128, 64, 32, 16],\n",
    "    \"output_dim\":1,\n",
    "}\n",
    "\n",
    "uqmodel = DistanceUQPINN(**model_args)\n",
    "\n",
    "alpha = 0.1\n",
    "k=30\n",
    "\n",
    "raw_heuristic = \"feature\"\n",
    "\n",
    "# Fit the data\n",
    "fit_args = dict(coloc_pt_num=200, X_train=X_train, Y_train=Y_train)\n",
    "fit_kwargs_grid = dict(\n",
    "    epochs=20000,\n",
    "    λ_pde= 1.0, λ_ic=10.0, λ_data=3.0,\n",
    "    lr=1e-3, stop_schedule=40000\n",
    ")\n",
    "print(f\"\\n[🟠] Training...\")\n",
    "baseline_loss_dict = uqmodel.fit(**fit_args, **fit_kwargs_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inferencing\n",
    "baseline_pred_kwargs = dict(n_samples=40, heuristic_u=raw_heuristic)\n",
    "print(f\"\\n[🟠] Base Model Inferencing...\")\n",
    "cp_uncal_predset = uqmodel.predict(alpha, grid_test, \n",
    "                                   **baseline_pred_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d87014",
   "metadata": {},
   "source": [
    "# Adaptive Scaled CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95668499",
   "metadata": {},
   "outputs": [],
   "source": [
    " # CP Model (Adaptive)\n",
    "from utils_extension.utils_uq_adapcp import AdaptiveCP, adaptive_cp_test_uncertainties_grid\n",
    "adap_kwarg={\n",
    "    \"alpha\":alpha,\n",
    "    \"heuristic\":raw_heuristic,\n",
    "    \"conf_nn_hidden_layers\":(16, 32, 64, 128, 128, 64, 32, 16),\n",
    "    \"conf_nn_lr\":1e-4,\n",
    "    \"conf_nn_epochs\":15000\n",
    "}\n",
    "adap_cp = AdaptiveCP(uqmodel, **adap_kwarg)\n",
    "adp_cp_cal_predset = adap_cp.predict(\n",
    "    alpha=alpha, X_test=grid_test, X_train=X_train, Y_train=Y_train,\n",
    "    X_cal=X_calibration, Y_cal=Y_calibration, k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_plot(\n",
    "    plot_1d_intervals_comparison,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_predset\"\n",
    ")(\n",
    "    X_test=grid_test,\n",
    "    uncal_interval=cp_uncal_predset,\n",
    "    cp_intervals=adp_cp_cal_predset,\n",
    "    uncal_interval_label=\"Naive UQ Band\",\n",
    "    cal_interval_label=\"Adaptive Scaled CP Band\",\n",
    "    true_solution=pde.true_solution,            # pass the function\n",
    "    t_train=X_vis,\n",
    "    y_train=Y_vis,\n",
    "    title=\"0.05-Alpha Level Adaptive Scaled Conformal Calibrated Prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71a97f3",
   "metadata": {},
   "source": [
    "# Normal Scaled CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ed065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal CP\n",
    "cp_pred_kwargs = {\n",
    "        \"X_train\":X_train,  \"Y_train\":Y_train,\n",
    "        \"X_cal\":X_calibration, \"Y_cal\":Y_calibration,\n",
    "        \"heuristic_u\":raw_heuristic,  # Change this based on cp\n",
    "        \"k\":k\n",
    "}\n",
    "from utils_uqmd.utils_uq_cp import CP\n",
    "cp_model = CP(uqmodel)\n",
    "cp_cal_predset = cp_model.predict(\n",
    "            alpha=alpha, X_test=grid_test,\n",
    "            **cp_pred_kwargs\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ac710",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_1d_intervals_comparison,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"cp_predset\"\n",
    ")(\n",
    "    X_test=grid_test,\n",
    "    uncal_interval=cp_uncal_predset,\n",
    "    cp_intervals=cp_cal_predset,\n",
    "    true_solution=pde.true_solution, \n",
    "    uncal_interval_label=\"Naive UQ Band\",\n",
    "    cal_interval_label=\"Scaled CP Band\",\n",
    "    t_train=X_vis,\n",
    "    y_train=Y_vis,\n",
    "    title=\"0.05-Alpha Level Scaled Conformal Calibrated Prediction\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5641478f",
   "metadata": {},
   "source": [
    "# Visual Comparison: Scaled CP v.s. Adaptive Scaled CP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30211a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vis, Y_test, sigma_test = add_heteroscedastic_noise_islands(X_test, Y_test, return_sigma=True)\n",
    "\n",
    "import torch, numpy as np\n",
    "\n",
    "def as_long_idx(idx, device):\n",
    "    if isinstance(idx, np.ndarray):\n",
    "        return torch.as_tensor(idx, dtype=torch.long, device=device)\n",
    "    elif not torch.is_tensor(idx):\n",
    "        return torch.as_tensor(idx, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        return idx.to(device=device, dtype=torch.long)\n",
    "\n",
    "idx = as_long_idx(id_test, X_test.device)\n",
    "\n",
    "# 1a) in-range, 1-D, non-empty\n",
    "assert idx.ndim == 1 and idx.numel() > 0, \"[idx] empty or not 1-D\"\n",
    "assert (0 <= idx.min()) and (idx.max() < X_test.shape[0]), \"[idx] out of range\"\n",
    "\n",
    "# 1b) duplicates?\n",
    "num_dup = idx.numel() - torch.unique(idx).numel()\n",
    "print(f\"[idx] duplicates = {num_dup}\")\n",
    "\n",
    "# 1c) monotone (only for info; non-monotone is OK)\n",
    "inversions = int((torch.diff(X_test[idx].view(-1)) < 0).sum().item())\n",
    "print(f\"[idx] inversions (non-monotone count) = {inversions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plot(\n",
    "    plot_1d_intervals_comparison,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_vs_cp_predset\"\n",
    ")(\n",
    "    X_test=grid_test,\n",
    "    uncal_interval=cp_cal_predset,\n",
    "    cp_intervals=adp_cp_cal_predset,\n",
    "    true_solution=pde.true_solution,            \n",
    "    uncal_interval_label=\"CP\",\n",
    "    cal_interval_label=\"Local CP\",\n",
    "    t_train=X_vis,\n",
    "    y_train=Y_vis,\n",
    ")\n",
    "\n",
    "plot_1d_intervals_comparison(\n",
    "    X_test=grid_test,\n",
    "    uncal_interval=cp_cal_predset,\n",
    "    cp_intervals=adp_cp_cal_predset,\n",
    "    true_solution=pde.true_solution,            \n",
    "    uncal_interval_label=\"CP\",\n",
    "    cal_interval_label=\"Local CP\",\n",
    "    t_train=X_vis,\n",
    "    y_train=Y_vis,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c5b59",
   "metadata": {},
   "source": [
    "# Bar Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c578930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_extension_vis_1d import local_noise_max_from_xy, plot_local_error_grid_2x2\n",
    "\n",
    "X_bar, Y_bar = pde.data_generation_uniform(3000)\n",
    "Y_bar_clean = Y_bar.clone()\n",
    "id_bar, Y_bar   = add_heteroscedastic_noise_islands(X_bar,  Y_bar_clean, baseline=0.05)\n",
    "true_err, _, _ = local_noise_max_from_xy(X_bar, Y_bar, k=5, metric=\"mae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff2290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_uncal_predset = uqmodel.predict(alpha, X_bar, \n",
    "                                   **baseline_pred_kwargs)\n",
    "\n",
    "cp_cal_predset = cp_model.predict(\n",
    "            alpha=alpha, X_test=X_bar,\n",
    "            **cp_pred_kwargs\n",
    "            )\n",
    "\n",
    "adp_cp_cal_predset = adap_cp.predict(\n",
    "    alpha=alpha, X_test=X_bar, X_train=X_train, Y_train=Y_train,\n",
    "    X_cal=X_calibration, Y_cal=Y_calibration, k=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67d2953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y are torch tensors\n",
    "\n",
    "# true_err= theoretical_noise_uniform(\n",
    "#     3000, (0.0, 5.0)\n",
    "# )\n",
    "heu_width = (cp_uncal_predset[1]- cp_uncal_predset[0])/2\n",
    "cp_width = (cp_cal_predset[1]- cp_cal_predset[0])/2\n",
    "adap_width = (adp_cp_cal_predset[1]- adp_cp_cal_predset[0])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93173c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbar = 34\n",
    "from utils_tools.utils_extension_vis_1d import plot_local_error_grid_2x2\n",
    "save_plot(\n",
    "    plot_local_error_grid_2x2,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"bar_plots\"\n",
    ")(\n",
    "    X_test=X_bar,\n",
    "    true_err=true_err,\n",
    "    heu_width=heu_width, \n",
    "    cp_width=cp_width,\n",
    "    adap_width=adap_width,\n",
    "    sharey=True,   # optional same y-scale\n",
    "    ylims = ((0, 0.9),(0, 0.9),(0, 0.9),(0, 0.9)),\n",
    "    nbar=(nbar,nbar,nbar,nbar)\n",
    ")\n",
    "\n",
    "plot_local_error_grid_2x2(\n",
    "    X_test=X_bar,\n",
    "    true_err=true_err,\n",
    "    heu_width=heu_width, \n",
    "    cp_width=cp_width,\n",
    "    adap_width=adap_width,\n",
    "    sharey=True,   # optional same y-scale\n",
    "    ylims = ((0, 0.9),(0, 0.9),(0, 0.9),(0, 0.9)),\n",
    "    nbar=(nbar,nbar,nbar,nbar)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a22c2d",
   "metadata": {},
   "source": [
    "# Test Model Local Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af8e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid, cp_test_uncertainties_in_noisy_region\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(20)\n",
    "\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": cp_model,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":20\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": uqmodel,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"idx_noisy_test\":id_test,\n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":20\n",
    "}\n",
    "cp_df_local = cp_test_uncertainties_in_noisy_region(**cp_testing_args)\n",
    "adap_df_local = adaptive_cp_test_uncertainties_grid(**adapcp_testing_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a1b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_result_viz import plot_dual_expected_vs_empirical\n",
    "import pandas as pd\n",
    "def plot_dual_expected_vs_empirical(\n",
    "    df_uncal,\n",
    "    df_cal,\n",
    "    *,\n",
    "    alpha_col=\"alpha\",\n",
    "    cov_col=\"coverage\",\n",
    "    title1=\"Uncalibrated Model\",\n",
    "    title2=\"Calibrated Model\",\n",
    "    dev_metric=\"mae\",\n",
    "    main_title=\"Coverage: Uncalibrated vs Calibrated\",\n",
    "    figsize=(12, 6),\n",
    "    constrained=True,           # set False if you prefer tight_layout()\n",
    "    title_pad=14,               # vertical offset for the figure title\n",
    "    tight_rect=(0, 0, 1, 0.96), # head-room if constrained=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Side-by-side coverage plots for uncalibrated and calibrated models.\n",
    "\n",
    "    The subtitle of each panel shows the deviation from ideal calibration\n",
    "    (MAE / RMSE / max absolute error).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_uncal, df_cal : pd.DataFrame\n",
    "        Must contain columns `alpha_col` and `cov_col`.\n",
    "    dev_metric : {\"mae\", \"rmse\", \"max\"}\n",
    "        Metric used for the deviation shown under each panel title.\n",
    "    main_title : str or None\n",
    "        Figure-level title.  Set None to suppress it.\n",
    "    constrained : bool\n",
    "        Use Matplotlib’s constrained-layout engine (recommended).\n",
    "        If False, the function falls back to tight_layout with `tight_rect`.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # helpers\n",
    "    def _prepare(df):\n",
    "        exp = 1.0 - df[alpha_col]\n",
    "        emp = df[cov_col]\n",
    "        exp_full = pd.concat([pd.Series([0.0]), exp, pd.Series([1.0])],\n",
    "                             ignore_index=True)\n",
    "        emp_full = pd.concat([pd.Series([0.0]), emp, pd.Series([1.0])],\n",
    "                             ignore_index=True)\n",
    "        order = exp_full.argsort()\n",
    "        return exp_full[order].to_numpy(), emp_full[order].to_numpy()\n",
    "\n",
    "    def _deviation(e, m, how):\n",
    "        diff = np.abs(m - e)\n",
    "        if how == \"mae\":\n",
    "            return diff.mean()\n",
    "        if how == \"rmse\":\n",
    "            return np.sqrt((diff ** 2).mean())\n",
    "        if how == \"max\":\n",
    "            return diff.max()\n",
    "        raise ValueError(\"dev_metric must be 'mae', 'rmse', or 'max'\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # data + metrics\n",
    "    exp1, emp1 = _prepare(df_uncal)\n",
    "    exp2, emp2 = _prepare(df_cal)\n",
    "    dev1 = _deviation(exp1, emp1, dev_metric)\n",
    "    dev2 = _deviation(exp2, emp2, dev_metric)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # figure & axes\n",
    "    if constrained:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize,\n",
    "                                 constrained_layout=True)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # panel 1 – uncalibrated\n",
    "    axes[0].plot(exp1, emp1, marker=\"o\", label=\"Empirical\")\n",
    "    axes[0].plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Ideal  y=x\")\n",
    "    axes[0].set_title(f\"{title1}\\nDeviation ({dev_metric.upper()}): {dev1:.3f}\")\n",
    "    axes[0].set_xlabel(\"Expected Coverage  (1 − α)\")\n",
    "    axes[0].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # panel 2 – calibrated\n",
    "    axes[1].plot(exp2, emp2, marker=\"o\", label=\"Empirical\")\n",
    "    axes[1].plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Ideal  y=x\")\n",
    "    axes[1].set_title(f\"{title2}\\nDeviation ({dev_metric.upper()}): {dev2:.3f}\")\n",
    "    axes[1].set_xlabel(\"Expected Coverage  (1 − α)\")\n",
    "    axes[1].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # figure-level title and layout finish\n",
    "    if main_title:\n",
    "        fig.suptitle(main_title, y=1.1, fontsize=12)\n",
    "\n",
    "    if not constrained:            # tidy up only if we skipped the CL engine\n",
    "        fig.tight_layout(rect=tight_rect)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "save_plot(\n",
    "    plot_dual_expected_vs_empirical,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_cp_coverage_plot_LOCAL\"\n",
    ")(cp_df_local, adap_df_local, title1=\"Scaled CP\", title2=\"Adaptive Scaled CP\", \n",
    "  main_title=\"Coverage Plot of Adaptive Conformal Prediction & Conformal Prediction Across Alpha Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_result_viz import plot_metrics_table\n",
    "\n",
    "df1=cp_df_local\n",
    "df2=adap_df_local\n",
    "df1_name=\"CP\" \n",
    "df2_name=\"Adaptive CP\"\n",
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_vs_cp_table_LOCAL\"\n",
    ")(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Adaptive Conformal Prediction and Conformal Prediction Metrics\")\n",
    "\n",
    "\n",
    "\n",
    "plot_metrics_table(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Adaptive Conformal Prediction and Conformal Prediction Metrics\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6a49c6",
   "metadata": {},
   "source": [
    "# Test model's Global coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80016192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Coverage comparison\n",
    "from utils_extension.utils_uq_adapcp import adaptive_cp_test_uncertainties_grid, cp_test_uncertainties_in_noisy_region\n",
    "from utils_tools.utils_result_metrics import cp_test_uncertainties\n",
    "# Conformal-prediction settings\n",
    "from utils_tools.utils_result_metrics import generating_alphas\n",
    "alphas = generating_alphas(20)\n",
    "\n",
    "\n",
    "cp_testing_args = {\n",
    "    \"uqmodel\": cp_model,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":20\n",
    "}\n",
    "adapcp_testing_args = {\n",
    "    \"base_md\": uqmodel,\n",
    "    \"alphas\":alphas, \n",
    "    \"X_test\":X_test, \"Y_test\":Y_test, \n",
    "    \"X_cal\":X_calibration, \"Y_cal\":Y_calibration, \n",
    "    \"X_train\":X_train, \"Y_train\":Y_train, \n",
    "    \"heuristic_u\":raw_heuristic, # Change base on if the baseline cp\n",
    "    \"k\":20\n",
    "}\n",
    "cp_df_global = cp_test_uncertainties(**cp_testing_args)\n",
    "adap_df_global = adaptive_cp_test_uncertainties_grid(**adapcp_testing_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b172a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_result_viz import plot_dual_expected_vs_empirical\n",
    "import pandas as pd\n",
    "def plot_dual_expected_vs_empirical(\n",
    "    df_uncal,\n",
    "    df_cal,\n",
    "    *,\n",
    "    alpha_col=\"alpha\",\n",
    "    cov_col=\"coverage\",\n",
    "    title1=\"Uncalibrated Model\",\n",
    "    title2=\"Calibrated Model\",\n",
    "    dev_metric=\"mae\",\n",
    "    main_title=\"Coverage: Uncalibrated vs Calibrated\",\n",
    "    figsize=(12, 6),\n",
    "    constrained=True,           # set False if you prefer tight_layout()\n",
    "    title_pad=14,               # vertical offset for the figure title\n",
    "    tight_rect=(0, 0, 1, 0.96), # head-room if constrained=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Side-by-side coverage plots for uncalibrated and calibrated models.\n",
    "\n",
    "    The subtitle of each panel shows the deviation from ideal calibration\n",
    "    (MAE / RMSE / max absolute error).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_uncal, df_cal : pd.DataFrame\n",
    "        Must contain columns `alpha_col` and `cov_col`.\n",
    "    dev_metric : {\"mae\", \"rmse\", \"max\"}\n",
    "        Metric used for the deviation shown under each panel title.\n",
    "    main_title : str or None\n",
    "        Figure-level title.  Set None to suppress it.\n",
    "    constrained : bool\n",
    "        Use Matplotlib’s constrained-layout engine (recommended).\n",
    "        If False, the function falls back to tight_layout with `tight_rect`.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # helpers\n",
    "    def _prepare(df):\n",
    "        exp = 1.0 - df[alpha_col]\n",
    "        emp = df[cov_col]\n",
    "        exp_full = pd.concat([pd.Series([0.0]), exp, pd.Series([1.0])],\n",
    "                             ignore_index=True)\n",
    "        emp_full = pd.concat([pd.Series([0.0]), emp, pd.Series([1.0])],\n",
    "                             ignore_index=True)\n",
    "        order = exp_full.argsort()\n",
    "        return exp_full[order].to_numpy(), emp_full[order].to_numpy()\n",
    "\n",
    "    def _deviation(e, m, how):\n",
    "        diff = np.abs(m - e)\n",
    "        if how == \"mae\":\n",
    "            return diff.mean()\n",
    "        if how == \"rmse\":\n",
    "            return np.sqrt((diff ** 2).mean())\n",
    "        if how == \"max\":\n",
    "            return diff.max()\n",
    "        raise ValueError(\"dev_metric must be 'mae', 'rmse', or 'max'\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # data + metrics\n",
    "    exp1, emp1 = _prepare(df_uncal)\n",
    "    exp2, emp2 = _prepare(df_cal)\n",
    "    dev1 = _deviation(exp1, emp1, dev_metric)\n",
    "    dev2 = _deviation(exp2, emp2, dev_metric)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # figure & axes\n",
    "    if constrained:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize,\n",
    "                                 constrained_layout=True)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    # panel 1 – uncalibrated\n",
    "    axes[0].plot(exp1, emp1, marker=\"o\", label=\"Empirical\")\n",
    "    axes[0].plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Ideal  y=x\")\n",
    "    axes[0].set_title(f\"{title1}\\nDeviation ({dev_metric.upper()}): {dev1:.3f}\")\n",
    "    axes[0].set_xlabel(\"Expected Coverage  (1 − α)\")\n",
    "    axes[0].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # panel 2 – calibrated\n",
    "    axes[1].plot(exp2, emp2, marker=\"o\", label=\"Empirical\")\n",
    "    axes[1].plot([0, 1], [0, 1], \"--\", color=\"gray\", label=\"Ideal  y=x\")\n",
    "    axes[1].set_title(f\"{title2}\\nDeviation ({dev_metric.upper()}): {dev2:.3f}\")\n",
    "    axes[1].set_xlabel(\"Expected Coverage  (1 − α)\")\n",
    "    axes[1].set_ylabel(\"Empirical Coverage\")\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # figure-level title and layout finish\n",
    "    if main_title:\n",
    "        fig.suptitle(main_title, y=1.1, fontsize=12)\n",
    "\n",
    "    if not constrained:            # tidy up only if we skipped the CL engine\n",
    "        fig.tight_layout(rect=tight_rect)\n",
    "\n",
    "    return fig, axes\n",
    "\n",
    "save_plot(\n",
    "    plot_dual_expected_vs_empirical,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_cp_coverage_plot_GLOBAL\"\n",
    ")(cp_df_global, adap_df_global, title1=\"CP\", title2=\"Adaptive CP\", \n",
    "  main_title=\"Coverage Plot of Adaptive Conformal Prediction & Conformal Prediction Across Alpha Levels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da997d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_tools.utils_result_viz import plot_metrics_table\n",
    "\n",
    "df1=cp_df_global\n",
    "df2=adap_df_global\n",
    "df1_name=\"CP\" \n",
    "df2_name=\"Adaptive CP\"\n",
    "save_plot(\n",
    "    plot_metrics_table,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"adpcp_vs_cp_table_GLOBAL\"\n",
    ")(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Adaptive Conformal Prediction and Conformal Prediction Metrics\")\n",
    "\n",
    "\n",
    "plot_metrics_table(None,None,None,None,df1,df2,df1_name,df2_name, alpha_level=0.05, \n",
    "  main_title=\"Adaptive Conformal Prediction and Conformal Prediction Metrics\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coverage_grid_1x2_centered_legend(\n",
    "    named_pairs,\n",
    "    *,\n",
    "    labels=(\"Local CP\",\"CP\"),\n",
    "    grid_figsize=(17, 7.5),\n",
    "    suptitle=None,\n",
    "    model_title_size=22,\n",
    "    middle_ratio=0.35,   # adjust space for legend between plots\n",
    "    float_labels=((\"Partial\", r\"$x \\in [0.8, 1.2] \\cup [1.8, 2.2] \\cup [2.8, 3.2]}$\"), (\"Global\", r\"$x \\in [0,5]$\")),  # new floating labels\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot 2 coverage plots side by side with the legend box\n",
    "    placed directly in the middle between them. Each plot\n",
    "    gets a floating text label at the upper-left corner.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    def _prep(df):\n",
    "        exp = 1.0 - df[\"alpha\"].to_numpy()\n",
    "        emp = df[\"coverage\"].to_numpy()\n",
    "        exp = np.concatenate(([0.0], exp, [1.0]))\n",
    "        emp = np.concatenate(([0.0], emp, [1.0]))\n",
    "        i = np.argsort(exp)\n",
    "        return exp[i], emp[i]\n",
    "\n",
    "    items = list(named_pairs.items()) if isinstance(named_pairs, dict) else list(named_pairs)\n",
    "    if len(items) != 2:\n",
    "        raise ValueError(\"Provide exactly 2 (name, df_uncal, df_cal) pairs.\")\n",
    "\n",
    "    # 1x3 layout: [plot1 | legend | plot2]\n",
    "    fig, axs = plt.subplots(\n",
    "        1, 3,\n",
    "        figsize=grid_figsize,\n",
    "        sharey=True,\n",
    "        gridspec_kw={\"width_ratios\": [1.0, middle_ratio, 1.0]}\n",
    "    )\n",
    "\n",
    "    legend_handles, legend_labels = None, None\n",
    "\n",
    "    # Left and right plots\n",
    "    for ax_plot, (name, df_uncal, df_cal), flabel in zip([axs[0], axs[2]], items, float_labels):\n",
    "        exp1, emp1 = _prep(df_uncal)\n",
    "        exp2, emp2 = _prep(df_cal)\n",
    "        ax_plot.plot(exp1, emp1, 'o-', color=\"#3245b1\", markerfacecolor=\"#6988ef\",\n",
    "                     ms=16, lw=5, label=labels[1])\n",
    "        ax_plot.plot(exp2, emp2, '*-', color=\"#b13c32\", markerfacecolor=\"#ed8076\",\n",
    "                     ms=22, lw=5, label=labels[0])\n",
    "        \n",
    "        ax_plot.plot([0, 1], [0, 1], '--', color='gray', label='Ideal (y=x)')\n",
    "\n",
    "        if legend_handles is None:\n",
    "            legend_handles, legend_labels = ax_plot.get_legend_handles_labels()\n",
    "\n",
    "        ax_plot.set_xlabel(\"Expected Coverage (1 − α)\", fontsize=20)\n",
    "        ax_plot.autoscale(enable=True, tight=False)\n",
    "        ax_plot.margins(x=0.02, y=0.02)\n",
    "        ax_plot.set_title(name, fontsize=model_title_size)\n",
    "        ax_plot.tick_params(axis='both', labelsize=15)\n",
    "\n",
    "        # floating label in upper-left corner\n",
    "        ax_plot.text(\n",
    "            0.02, 0.98, flabel[0],\n",
    "            transform=ax_plot.transAxes,\n",
    "            fontsize=25, \n",
    "            fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "        ax_plot.text(\n",
    "            0.02, 0.9, flabel[1],\n",
    "            transform=ax_plot.transAxes,\n",
    "            fontsize=20, \n",
    "            fontweight=\"bold\",\n",
    "            va=\"top\", ha=\"left\",\n",
    "            bbox=dict(facecolor=\"white\", alpha=0.6, edgecolor=\"none\", boxstyle=\"round,pad=0.3\")\n",
    "        )\n",
    "        \n",
    "\n",
    "    axs[0].set_ylabel(\"Empirical Coverage\", fontsize=20)\n",
    "\n",
    "    # Middle subplot: legend only\n",
    "    axs[1].axis(\"off\")\n",
    "    axs[1].legend(\n",
    "        legend_handles, legend_labels,\n",
    "        loc=\"lower center\", frameon=True, fontsize=20, ncol=1\n",
    "    )\n",
    "\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle, fontsize=model_title_size + 2, y=0.98)\n",
    "\n",
    "    fig.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    return fig, axs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781209b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [\n",
    "    (\"\",    cp_df_local,  adap_df_local),\n",
    "    (\"\", cp_df_global,    adap_df_global),\n",
    "]\n",
    "fig, axs = plot_coverage_grid_1x2_centered_legend(pairs)\n",
    "save_plot(\n",
    "    plot_coverage_grid_1x2_centered_legend,\n",
    "    save_dir=\"Adaptive_scaled_CP\",\n",
    "    prefix=\"coverage_sets\"\n",
    ")(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7afab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean\n",
    "pred_set_plot = uqmodel.predict(alpha, X_test, \n",
    "                            **baseline_pred_kwargs)\n",
    "pred_mean_plot = (pred_set_plot[0] + pred_set_plot[1])/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
